{
    "color_dict": {
        "brain synchrony": "Color_6", 
        "physiological concordance index": "Color_6", 
        "Signal Matching (SM)": "Color_6", 
        "Pearson‚Äôs correlation (PC)": "Color_6", 
        "Directional Agreement (DA)": "Color_6", 
        "physiological synchrony (DA)": "Color_6", 
        "WC - EDA": "Color_6", 
        "Physiological linkage": "Color_6", 
        "Physiological synchrony": "Color_6", 
        "Pearson‚Äôs correlation coefficient (PCC)": "Color_6", 
        "IDM - EDA": "Color_6", 
        "Fisher‚Äôs z-transform (FZT)": "Color_6", 
        "DA - EDA": "Color_6", 
        "EDA peak detection": "Color_6", 
        "SM - EDA": "Color_6", 
        "Galvanic skin response": "Color_6", 
        "CC - EDA": "Color_6", 
        "physiological synchrony": "Color_6", 
        "Instantaneous Derivative Matching (IDM)": "Color_6", 
        "EDA synchrony": "Color_6", 
        "cycles of physiological synchrony (PC)": "Color_6", 
        "physiological synchrony (PC)": "Color_6", 
        "Gaze saccade": "Color_1", 
        "Gaze transitions": "Color_1", 
        "gaze saccades": "Color_1", 
        "Facial expression": "Color_4", 
        "22 Intra-Personal Features": "Color_4", 
        "facial features": "Color_4", 
        "facial expression": "Color_4", 
        "smiling synchrony": "Color_4", 
        "facial expression features (60 features)": "Color_4", 
        "51 Facial Action Units": "Color_4", 
        "9 Dyadic Features": "Color_4", 
        "head/body movement": "Color_3", 
        "amount of movement": "Color_3", 
        "amount of face and body movement": "Color_3", 
        "Total Movement": "Color_3", 
        "body pose": "Color_3", 
        "Face and upper body movement": "Color_3", 
        "x,y,z body joints": "Color_3", 
        "upper body agitation": "Color_3", 
        "Total movement across upper body joints and body parts": "Color_3", 
        "Body motion": "Color_3", 
        "Joint movement": "Color_3", 
        "Physical synchrony": "Color_3", 
        "Body synchronization": "Color_3", 
        "Joint angle": "Color_3", 
        "body synchronization": "Color_3", 
        "type of movement": "Color_3", 
        "Motion energy images": "Color_3", 
        "Iconic gestures per second": "Color_3", 
        "gesture": "Color_3", 
        "Mean distance between hands": "Color_3", 
        "hand agitation": "Color_3", 
        "gesture type and location": "Color_3", 
        "clustered hand/wrist movement": "Color_3", 
        "Mean hand movement speed": "Color_3", 
        "Distance between hands": "Color_3", 
        "Deictic gestures per second": "Color_3", 
        "Total manual gestures per second": "Color_3", 
        "head orientation": "Color_4", 
        "Number of faces looking at screen": "Color_4", 
        "Head motion features [x5]": "Color_4", 
        "Head motion": "Color_4", 
        "Faces looking at screen (FLS)": "Color_4", 
        "WC - HR low frequency": "Color_6", 
        "DA - HR": "Color_6", 
        "WC - HR high frequency": "Color_6", 
        "IDM - HR": "Color_6", 
        "heart rate sychrony": "Color_6", 
        "SM - HR": "Color_6", 
        "CC - HR": "Color_6", 
        "dyad proximity": "Color_3", 
        "Distance between learners (DBL)": "Color_3", 
        "Mean distance between learners": "Color_3", 
        "time spent individually": "Color_3", 
        "Body distance": "Color_3", 
        "transition probabilities between collaborative state": "Color_3", 
        "time spent as a group": "Color_3", 
        "Distance from the center of the table": "Color_3", 
        "Times numbers were mentioned": "Color_5", 
        "linguistic features from transcript (65 features)": "Color_5", 
        "linguistic features": "Color_5", 
        "Linguistic features [x300+]": "Color_5", 
        "Sequences of verbal utterances": "Color_5", 
        "convergence (of linguistic styles)": "Color_5", 
        "coherence": "Color_5", 
        "dialogue acts": "Color_5", 
        "speech utterances": "Color_5", 
        "Times commands were pronounced": "Color_5", 
        "simple linguistic features": "Color_5", 
        "Times mathematical terms were mentioned": "Color_5", 
        "Dialogue episodes (description, management)": "Color_5", 
        "Audio level (AUD)": "Color_5", 
        "thousands of features prosodic speech": "Color_5", 
        "prosodic and tone features [many]": "Color_5", 
        "1582 audio features (from Emobase)": "Color_5", 
        "speech features": "Color_5", 
        "audio energy features": "Color_5", 
        "88 GeMAPS acoustic features": "Color_5", 
        "speech rate": "Color_5", 
        "Mean audio level": "Color_5", 
        "Acoustic features [x13]": "Color_5", 
        "Convergence": "Color_5", 
        "Synchrony": "Color_5", 
        "102 extended GeMAPs acoustic features": "Color_5", 
        "Proximity": "Color_5", 
        "Energy": "Color_5", 
        "voice features (4 features)": "Color_5", 
        "6 One Vs All Features": "Color_5", 
        "peak slope": "Color_5", 
        "Pitch": "Color_5", 
        "Articulation rate": "Color_5", 
        "spectral stationarity": "Color_5", 
        "12 MFCCs": "Color_5", 
        "35 Coh-metrix indices": "Color_5", 
        "duration of overlapping speech from pairs of students": "Color_5", 
        "duration of overlapping speech from all people": "Color_5", 
        "Speech activity": "Color_5", 
        "(non)": "Color_5", 
        "speech time and frequency": "Color_5", 
        "speaking time / turns": "Color_5", 
        "probability of a transition from a vocalisation to floor": "Color_5", 
        "probability of a transition from floor (i.e. a pause, group switching pause or speaker switching pause)": "Color_5", 
        "number of active participants in group": "Color_5", 
        "verbal dominance and information metrics [9 metrics]": "Color_5", 
        "Silence and Overlap Cues (Fraction of Silence, Fraction of Nonoverlapped Speech, Fraction of two-people and three-people Overlapped Speech)": "Color_5", 
        "Total speech duration": "Color_5", 
        "uncertainty in the transitions (turn taking)": "Color_5", 
        "duration in which each student was only speaker": "Color_5", 
        "probability of transitioning from a speaker vocalisation to a group vocalisation": "Color_5", 
        "duration of all vocalisations": "Color_5", 
        "interruption": "Color_5", 
        "average duration of vocalisation": "Color_5", 
        "non-verbal speaking metrics (speaking length, interruptions, etc)": "Color_5", 
        "Speaking status": "Color_5", 
        "speech quantity": "Color_5", 
        "speech time": "Color_5", 
        "Number of interventions": "Color_5", 
        "Speaking turn features [x4]": "Color_5", 
        "Pause duration": "Color_5", 
        "standard deviation of vocalisation": "Color_5", 
        "Speaking Distribution Cues (Speaking Length Skew, Speaking Turns Skew, Successful Interruption Skew, Unsuccessful Interruptions Skew, Backchannels Skew)": "Color_5", 
        "duration of silence for all people": "Color_5", 
        "Speaking Activity (Speaking length, Speaking turns, Speaking interruptions, Average speaking turn duration)": "Color_5", 
        "symmetry of speech among group": "Color_5", 
        "talking time": "Color_5", 
        "transition probability between types of vocalisations": "Color_5", 
        "speaking time % per individual": "Color_5", 
        "Group Participation Speaking Cues (Speaking Length, Speaking Turns, Successful Interruptions, Unsuccessful Interruptions, Backchannels)": "Color_5", 
        "speaking turn duration / number": "Color_5", 
        "probability of transitioning from a group vocalisation to speaker vocalisation": "Color_5", 
        "verbal participation symmetry among group": "Color_5", 
        "duration of speech by each student": "Color_5", 
        "student work phases": "Color_2", 
        "types of exploration": "Color_2", 
        "Arduino active blocks": "Color_2", 
        "events": "Color_2", 
        "Arduino active software blocks": "Color_2", 
        "card movements": "Color_2", 
        "type of activity done in task": "Color_2", 
        "target for discussion partner": "Color_2", 
        "zooming": "Color_2", 
        "Arduino measure of complexity": "Color_2", 
        "Calculator Use": "Color_2", 
        "scrolling": "Color_2", 
        "zoid acceleration": "Color_2", 
        "Arduino active hardware blocks": "Color_2", 
        "movement of objects including revisiting past actions": "Color_2", 
        "physical participation quantity": "Color_2", 
        "Player actions": "Color_2", 
        "amount of exploration": "Color_2", 
        "N-grams": "Color_2", 
        "Cosine similarity scores": "Color_2", 
        "Convergence measures": "Color_2", 
        "Average stroke time length": "Color_2", 
        "Average stroke displacement": "Color_2", 
        "Average stroke pressure": "Color_2", 
        "Coherence metrics": "Color_2", 
        "Average stroke path length": "Color_2", 
        "Average number of points": "Color_2", 
        "Total number of pen strokes": "Color_2", 
        "total number of touch actions": "Color_2", 
        "Touch patterns": "Color_2", 
        "Sequences of meaningful actions": "Color_2", 
        "symmetry of touch actions among group": "Color_2", 
        "cognitive load (from pupil size)": "Color_1",
        "Audio-visual (Looking while speaking, Looking while listening, Being looked while speaking, Center of attention while speaking, Visual dominance ratio)": "Color_1", 
        "attention given by person": "Color_1", 
        "Cycles of collaborative / individual work": "Color_1", 
        "EVT of spatial entropy": "Color_1", 
        "visual focus of attention": "Color_1", 
        "Joint visual Attention": "Color_1", 
        "Individual Visual Focus of Attention": "Color_1", 
        "Gaze": "Color_1", 
        "Focused gaze": "Color_1", 
        "attention received per person": "Color_1", 
        "conceptual with-me-ness (gaze)": "Color_1", 
        "Gaze fixation": "Color_1", 
        "Gaze location": "Color_1", 
        "gaze fixations": "Color_1", 
        "joint visual attention": "Color_1", 
        "(not)": "Color_1", 
        "Together gaze": "Color_1", 
        "gaze similarity": "Color_1", 
        "perceptual with-me-ness (gaze)": "Color_1", 
        "shared gaze": "Color_1", 
        "Count of faces looking at screen": "Color_1", 
        "Joint visual attention": "Color_1", 
        "Group Looking Cues (Fraction of People Gaze, Fraction of Convergent Gaze, Fraction of Mutual Gaze, Fraction of Shared Gaze, Gaze Skew)": "Color_1", 
        "Multidimensional Recurrence Quantification Analysis (MdRQA)": "Color_1", 
        "visual focus of attention features": "Color_1", 
        "visual attention metrics [8 metrics]": "Color_1", 
        "joint-visual attention": "Color_1", 
        "visual field of attention on a person features": "Color_1", 
        "Network features [+20]": "Color_1", 
        "Cross-Recurrence Quantification Analysis (CRQA)": "Color_1"
    }
}