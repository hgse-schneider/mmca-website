paper_id_new,paper_id,coder,data,data_standardized,sensor,brand,metric,metric_larger_category,metric_smaller_category,metric_IG_category,data_per_metric,data_metric_method,outcome,outcome_instrument,outcome_smaller_category,outcome_larger_category,analysis_and_results mm-oo:analysis:resultsig
1,1,bert,III) Audio,III) Audio,III) microphone,III) NS,1) speech time,1) Verbal,1) Speech Features,1) individual,1) III,1) calculation,A) verbal participation,A) survey,A) communication,A) process,1-A: t-test: sig: (t[38] = 2.18)
2,3,bert,"I) Eye gaze
III) Audio","I) Eye gaze
III) Audio","I) eye-tracker
III) microphone","I) Tobii 1750
III) NS","1) focused gaze 
2) together gaze 
3) dialogue episode
4) gaze transitions","1) Gaze
2) Gaze
3) Verbal
4) Gaze","1) Visual Attention
2) Visual Attention
3) Speech Content
4) Eye Motion","1) individual
2) group
3) individual
4) individual","1) I
2) I
3) III
4) I","1) calculation (entropy)
2) calculation
3) calculation
4) calculation","A) program understanding
B) dialogue episodes","A) researcher codes
B) researcher codes","A) performance
B) coordination","A) product
B) process","1+2-A: anova: sig
1+2-A+B: mixed linear model: sig
4-B: anova: sig"
3,4,edwin,"VI) EDA
VII) ECG","VI) Physiological
VII) Physiological","VI) Varioport 16-bit digital skin conductance amplifier
VII) modified Lead II configuration","VI) Varioport-B portable recorder system
VII) NS",1) physiological linkage,1) Physiological,1) EDA,1) individual,1) VI&VII,1) correlation,"A) behavioral Involvement
B) empathy
C) negative Feelings
D) perceived comprehension","A) Social Presence in Gaming Questionnaire
B) Social Presence in Gaming Questionnaire
C) Social Presence in Gaming Questionnaire
D) Social Presence Inventory Questionnaire","A) cognitive engagement
B) affective
C) affective
D) learning","A) process
B) process
C) process
D) product","1-A: regression: sig
1-B: regression: sig
1-C: regression: sig
1-D: regression: sig"
4,5,iulian,"II) Video
III) Audio
X) Time of flight 3D map","II) Video
III) Audio
X) Body language","II) kinect
III) microphone
X) IRMA Matrix ToF sensors","II) Microsoft
III) not stated
X) Infrared Intelligent Systems","1) non-verbal speaking metrics
2) visual attention
3) verbal dominance and information metrics","1) Verbal
2) Gaze
3) Verbal","1) Speech Participation
2) Visual Attention
3) Speech Participation","1) individual
2) group
3) group","1) X
2) II
3) III","1) Calculation
2) Calculation
3) Calculation","A) perceived leadership
B) perceived contribution","A) questionnaire
B) questionnaire","A) interpersonal relationship / perception
B) interpersonal relationship / perception","A) process
B) process","3-A: correlation: sig
3-B: correlation: sig
1-A: correlation: nonsig
1-B: correlation: nonsig
2-A: correlation: nonsig
2-B: correlation: sig
1*2*3-A: regression: nonsig
1*2*3-B: regression: nonsig"
5,6,bert,"VI) EDA
II) Video","VI) Physiological
II) Video","VI) EDA sensor
II) camera","VI) Empatica
II) NS","1) eda peak detection 
2) physiological concordance index","1) Physiological
2) Physiological","1) EDA
2) Combined","1) individual
2) group","1) VI
2) II","1) calculation
2) calculation","A) monitoring of behavior, cognition, motivations and emotions ","A) Video coding of monitoring (behavior, cognition, motivations and emotions) ",A) cognitive engagement,A) process,"1,2-A: correlation: sig: (r=0.663)"
6,10,steph,"III) Audio
II) Video","III) Audio
II) Video","III) Microphone
II) camera","III) NS
II) Logitech R Webcam Pro 9000","1) group participation speaking cues
2) silence and overlap cues
3) speaking distribution cues
4) individual visual focus of attention
5) group looking cues","1) Verbal
2) Verbal
3) Verbal
4) Gaze
5) Gaze","1) Speech Participation
2) Speech Participation
3) Speech Participation
4) Visual Attention
5) Visual Attention ","1) individual
2) group
3) group
4) individual
5) group","1) III
2) III
3) III
4) II
5) II","1) Calculation
2) Calculation
3) Calculation
4) Maximum Aposteriori Rule
5) Calculation","A) group composition
B) group interpersonal perception
C) group performance","A) NEO-FFI questionnaire
B) Questionnaire
C) Negative distance between expert list and group list","A) group composition
B) interpersonal relationship / perception
C) performance","A) condition
B) process
C) product","1-A: correlation: sig
2-A: correlation: sig
3-A: correlation: sig
4-A: correlation: sig
5-A: correlation: sig
1-B: correlation: sig
2-B: correlation: sig
3-B: correlation: sig
4-B: correlation: sig
5-B: correlation: sig
1-C: correlation: sig
2-C: correlation: sig
3-C: correlation: sig
4-C: correlation: sig
5-C: correlation: sig
1+2-A: regression: sig
2+3-B: regression: sig
2-C: regression: sig"
7,11,edwin,"I) Audio
II) Video","I) Audio
II) Video","I) NS
II) NS","I) NS
II) NS","1) GeMAPS acoustic features
2) extended GeMAPs acoustic features
3) MFCCs
4) facial action units","1) Verbal
2) Verbal
3) Verbal
4) Head","1) Speech Features
2) Speech Features
3) Speech Features
4) Facial Expressions","1) individual
2) individual
3) individual
4) individual","1) I
2) I
3) I
4) II","1) other: OpenSMILE
2) other: OpenSMILE
3) other: OpenSMILE
4) other: OpenFace","A) voiced Laughter
B) unvoiced Laughter
C) speech Laughter","A) Voicing probability and unvoiced frame ratio
B) Voicing probability and unvoiced frame ratio
C) Human Annotations","A) interpersonal relationship / perception
B) interpersonal relationship / perception
C) interpersonal relationship / perception","A) process
B) process
C) process","1+2+3+4-A: sup. machine learning: nonsig
1+3+3+4-B: sup. machine learning: nonsig
1+2+3+4-C: sup. machine learning: nonsig"
8,12,bert,I) Audio,I) Audio,I) Microphone,I) NS,"1) speech features 
2) linguistic features","1) Verbal
2) Verbal","1) Speech Features
2) Speech Content","1) individual
2) individual","1) I
2) I ","1) calculation
2) calculation",A) group performance,A) group scores compared to expert scores,A) performance,A) product,1+2-A: sup. machine learning: (64.4%)
9,14,callie,I) Eye gaze,I) Eye gaze,I) eyetracker,I) NS,"1) perceptual with-me-ness (gaze)
2) conceptual with-me-ness (gaze)
3) gaze similarity ","1) Gaze
2) Gaze
3) Gaze","1) Visual Attention
2) Visual Attention
3) Visual Attention","1) individual
2) individual
3) group","1) I
2) I
3) I","1) calculation
2) calculation 
3) calculation",A) learning gains,A) pre-post test,A) learning,A) product,"1-A: correlation: sig: (r = 0.51)
2-A: correlation: sig: (r = 0.41)
3-A: correlation: sig: (r = 0.39)"
10,15,edwin,I) Eye gaze,I) Eye gaze,I) eye-tracking glasses,I) SMI,"1) gaze fixations
2) gaze saccades","1) Gaze
2) Gaze","1) Visual Attention
2) Eye Motion","1) individual
2) individual","1) I
2) I","1) other: BeGaze
2) other: BeGaze",A) reference-action sequence,A) researcher codes,A) performance,A) product,1+2-A: correlation: nonsig
11,17,steph,"II) Video
IV) Kinesiology
V) Log data","II) Video
IV) Body language
V) Log data","II) Kinect
IV) Kinect
V) own application","II) Microsoft Kinect
IV) Microsoft Kinect
V) JavaTutor","1) dialogue acts
2) facial expression
3) gesture
4) task actions","1) Verbal
2) Head
3) Body
4) Log Data","1) Speech Content
2) Facial Expressions
3) Hand Motion
4) Task-related","1) individual
2) individual
3) individual
4) individual","1) V
2) II
3) IV
4) V","1) sup machine learning
2) CERT
3) calculation
4) none","A) engagement
B) frustration
C) learning gains","A) participant self report
B) participant self report
C) pre-post test","A) cognitive engagement
B) affective
C) learning","A) process
B) process
C) product","1+2+3-A: regression: sig
1+2+3-B: regression: sig
1+2+3-C: regression: sig"
12,18,steph,"IV) Kinesiology
II) Video","IV) Body language
II) Video","IV) Kinect
II) camera","IV) Microsoft Kinect
II) NS","1) clustered hand/wrist movement
2) object manipulation","1) Body
2) Log Data","1) Hand Motion
2) Task-related","1) individual
2) individual","1) IV
2) II","1) unsupervised machine learning
2) human coding",A) learning gains,A) pre-post test (references to  principles or mechanisms that confer stability to three example structures) ,A) learning,A) product,1-A: sup. machine learning: sig: (ACC: 76%)
13,19,bert,"I) Eye gaze
II) Audio","I) Eye gaze
II) Audio","I) eye-tracker
II) Microphone","I) Tobii 1750
II) NS","1) (not) focused together
2) dialogue episodes","1) Gaze
2) Verbal","1) Visual Attention
2) Speech Content","1) group
2) individual","1) I
2) II","1) calculation
2) calculation",A) level of understanding,A) researcher codes,A) learning,A) product,"1-A: anova: sig: (F [1,16]=8.70)
1+2-A: anova: sig: (F [1,61]=7.60)"
14,20,edwin,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) NS,1) joint visual attention,1) Gaze,1) Visual Attention,1) group,1) I,1) calculation,"A) learning gains
B) collaboration quality","A) learning test
B) coding scheme","A) learning
B) coordination, communication","A) product
B) process","1-A: regression: sig
1-B: regression: sig"
15,21,edwin,V) Log data,V) Log data,V) interactive tabletop,V) NS,1) events,1) Log Data,1) Task-related ,1) individual,1) V,1) calculation,A) group performance,A) researcher codes,A) performance,A) product,1-A: unsup. machine learning: sig
16,22,edwin,"I) Eye gaze
V) Log data","I) Eye gaze
V) Log data","I) eye-tracker
V) NS","I) Tobii X1
V) NS","1) joint visual attention
2) n-grams
3) cosine similarity scores
4) convergence measures
5) coherence metrics","1) Gaze
2) Verbal
3) Verbal
4) Verbal
5) Verbal","1) Visual Attention
2) Speech Content
3) Speech Content
4) Speech Content
5) Speech Content","1) individual
2) individual
3) individual
4) individual
5) individual","1) I
2) V
3) V
4) V
5) V","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation","A) learning gains
B) collaboration quality","A) learning test
B) coding scheme","A) learning
B) coordination, communication","A) product
B) process","1,4-A: ANOVA: nonsig
1,4-B: ANOVA: nonsig
1,5-A: correlation: sig
2,3,4,5-A: sup. machine learning: 75%"
17,24,edwin,"I) Eye gaze
II) Video
III) Audio","I) Eye gaze
II) Video
III) Audio","I) eye-tracker
II) camera
III) microphone ","I) SMI Eye- Tracking Glasses with binocular pupil tracking at 30Hz
II) NS
III) NS","1) joint visual attention
2) gestures
3) speech duration","1) Gaze
2) Body
3) Verbal","1) Visual Attention
2) Hand Motion
3) Speech Participation","1) group
2) individual
3) individual","1) I
2) II
3) III","1) calculation
2) qualitative
3) calculation","A) group performance 
B) learning gains","A) researcher codes
B) learning test","A) performance
B) learning","A) product
B) product","1,2,3-B: qualitative: sig
1-B: correlation: sig"
18,25,edwin,"II) Video
III) Audio
V) Log data","II) Video
III) Audio
V) Log data","II) camera
III) microphone
V) digital pen","II) NS
III) NS
V) NS","1) calculator use
2) total movement
3) distance from the center of the table
4) number of interventions
5) speech duration
6) times numbers were mentioned
7) times mathematical terms were mentioned
8) times commands were pronounced
9) total number of pen strokes
10) average number of points
11) average stroke time length
12) average stroke path length
13) average stroke displacement
14) average stroke pressure","1) Log Data
2) Body
3) Body
4) Verbal
5) Verbal
6) Verbal
7) Verbal
8) Verbal
9) Log Data 
10) Log Data 
11) Log Data 
12) Log Data 
13) Log Data 
14) Log Data","1) Task-related
2) Gross Body Motion
3) Location
4) Speech Participation
5) Speech Participation
6) Speech Content
7) Speech Content
8) Speech Content
9) Text 
10) Text 
11) Text 
12) Text 
13) Text 
14) Text ","1) individual
2) individual
3) individual
4) group
5) individual
6) individual
7) individual
8) individual
9) individual
10) individual
11) individual
12) individual
13) individual
14) individual","1) II
2) II
3) II
4) III
5) III
6) III
7) III
8) III
9) V
10) V
11) V
12) V
13) V
14) V","1) other: OpenCV
2) other: Codebook algorithm
3) other: OpenTld
4) other: stats generator algorithm
5) other: stats generator algorithm
6) other: stats generator algorithm
7) other: stats generator algorithm
8) other: stats generator algorithm
9) other: Strontium
10) other: Strontium
11) other: Strontium
12) other: Strontium
13) other: Strontium
14) other: Strontium","A) odds of a student solving correctly a problem
B) expert prediction","A) researcher codes
B) researcher codes","A) performance
B) group composition","A) product
B) condition","1,2,3,4,5,6,7,8,9,10,11,12,13,14-A: regression: sig
1,2,3,4,5,6,7,8,9,10,11,12,13,14-B: sup. machine learning: sig"
19,26,edwin,"II) Video
III) Audio","II) Video
III) Audio","II) camera
III) microcone","II) NS
III) Dev-Audio","1) speaking status
2) pitch
3) energy
4) head motion
5) body motion
6) motion energy images
7) gaze","1) Verbal
2) Verbal
3) Verbal
4) Head
5) Body
6) Body
7) Gaze","1) Speech Participation
2) Speech Features
3) Speech Features
4) Head Motion
5) Gross Body Motion
6) Gross Body Motion
7) Visual Attention","1) group
2) individual
3) individual
4) individual
5) individual
6) individual
7) group","1) III
2) III
3) III
4) II
5) II
6) II
7) II","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation
6) calculation
7) calculation",A) personality traits,"A) self-reported survey , researcher codes",A) group composition,A) condition,"1,2,3,4,5,6,7-A: unsup. machine learning: (69.61%)"
20,27,edwin,"II) Video
III) Audio
V) Log data","II) Video
III) Audio
V) Log data","II) camera
III) microphone
V) digital pen and digital paper","II) Point Grey Scorpion digital firewire cameras
III) Countryman Isomax hyper-cardioid microphones
V) Nokia digital pens and Anoto digital paper","1) total manual gestures per second
2) iconic gestures per second
3) deictic gestures per second","1) Body
2) Body
3) Body","1) Hand Motion
2) Hand Motion
3) Hand Motion","1) individual
2) individual
3) individual","1) II
2) II
3) II","1) qualitative
2) qualitative
3) qualitative",A) expertise,A) researcher codes,A) group composition,A) condition,"1-A: Wilcoxon Signed Ranks test: sig
2-A: Wilcoxon Signed Ranks test: sig
3-A: Wilcoxon Signed Ranks test: nonsig"
21,28,edwin,"III) Audio
V) Log data","III) Audio
V) Log data","III) microphone
V) interactive tabletop","III) Dev-Audio
V) Collaid","1) sequences of verbal utterances
2) sequences of meaningful actions","1) Verbal
2) Log Data","1) Speech Content
2) Touch ","1) individual
2) individual","1) III
2) V","1) qualitative
2) qualitative",A) colloboration quality,A) researcher codes,"A) coordination, communication",A) process,"1,2-A: unsup. machine learning: (90%)"
22,32,callie,III) Audio,III) Audio,III) microphone,III) NS,"1) duration of all vocalisations
2) average duration of vocalisation
3) standard deviation of vocalisation
4) probability of a transition from floor to a vocalisation
5) probability of a transition from a vocalisation to floor
6) probability of transitioning from a group vocalisation to speaker vocalisation
7) probability of transitioning from a speaker vocalisation to a group vocalisation
8) uncertainty in the transitions originating from a speaker","1) Verbal
2) Verbal
3) Verbal
4) Verbal
5) Verbal
6) Verbal
7) Verbal
8) Verbal","1) Speech Participation
2) Speech Participation
3) Speech Participation
4) Speech Participation
5) Speech Participation
6) Speech Participation
7) Speech Participation
8) Speech Participation","1) individual
2) individual
3) individual
4) individual
5) individual
6) individual
7) individual
8) group","1) III
2) III
3) III
4) III
5) III
6) III
7) III
8) III","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation
6) calculation
7) calculation
8) calculation",A) identity of the expert,"A) student with the highest cumulative score of points assigned to correctly and incorrectly solved problems, weighted according a discrete diffculty level scale",A) group composition,A) condition,"1,2,3,4,5,6,7,8-A: sup. machine learning: sig: (ACC: 92%)"
23,33,callie,"IV) Kinesiology
V) Log data","IV) Body language
V) Log data","IV) Kinect
V) Own application","IV) Microsoft Kinect
V) Created","1) amount of exploration
2) types of exploration
3) amount of movement
4) type of movement
5) body synchronization
6) body distance","1) Log Data
2) Log Data
3) Body
4) Body
5) Body
6) Body","1) Task-related
2) Task-related
3) Gross Body Motion
4) Gross Body Motion
5) Gross Body Motion
6) Location","1) individual
2) individual
3) individual
4) group
5) individual
6) individual","1) V
2) V
3) IV
4) IV
5) IV
6) IV","1) calculation
2) calculation
3) calculation
4) unsup machine learning
5) calculation
6) calculation","A) individual learning gains
B) group learning gains
C) leadership","A) pre-post test
B) pre-post test
C) coding","A) learning
B) learning
C) group composition","A) product
B) product
C) condition","1-A: correlation: nonsig
2-A: correlation: mixed
3-A: correlation: nonsig
4-A: correlation: sig
4-C: ANOVA: sig
5-A: ANOVA: nonsig
6-A: correlation: nonsig
1+2+3+4+5+6-B: sup. machine learning: sig: (ACC: 100%)"
24,39,bert,"VI) EDA
II) Audio","VI) Physiological
II) Audio","VI) Smart Wristband
II) Microphone ","VI) Empatica E4
II) Kinect Microphone","1) physiological synchrony (PC)
2) physiological synchrony (DA)
3) physiological synchrony (SM)
4) physiological synchrony (IDM)
5) cycles of physiological synchrony (PC)","1) Physiological
2) Physiological
3) Physiological
4) Physiological
5) Physiological","1) EDA
2) EDA
3) EDA
4) EDA
5) EDA","1) group
2) group
3) group
4) group
5) group","1) VI
2) VI
3) VI
4) VI
5) VI","1) Calculation
2) Calculation
3) Calculation
4) Calculation
5) Calculation","A) collaboration quality
B) task performance
C) learning gains","A) Meier, Spada and Rummel coding scheme
B) Performance score
C) pre-post test","A) coordination, communication
B) performance
C) learning","A) process
B) product
C) product","1-C: correlation: sig: r = 0.35
2-A: correlation: sig: r =0.47
5-A: correlation: sig: r = 0.57
5-C: correlation: sig: r = 0.47"
25,40,edwin,"I) Audio
II) Video
VI) EDA","I) Audio
II) Video
VI) Physiological","I) microphone
II) webcam
VI) electrodes","I) NS
II) NS
VI) Shimmer 3 GSR+","1) speech rate
2) face and upper body movement
3) galvanic skin response","1) Verbal
2) Body
3) Physiological","1) Speech Features
2) Gross Body Motion
3) EDA","1) individual
2) individual
3) individual","1) I
2) II
3) VI","1) sup machine learning
2) sup machine learning
3) calculation","A) perceived collaboration quality
B) perceived valence
C) perceived arousal
D) task performance","A) Questionnaire
B) 5-point Likert scale
C) 5-point Likert scale
D) Trophies earned","A) interpersonal relationship / perception, coordination
B) affective
C) affective
D) performance","A) process
B) process
C) process
D) product","1+2+3-A: unsup. machine learning: nonsig
1+2+3-B: unsup. machine learning: nonsig
1+2+3-C: unsup. machine learning: nonsig
1+2+3-D: unsup. machine learning: nonsig"
26,41,bert,I) Eye gaze,I) Eye gaze,I) eyetracker,I) Tobii Glasses,"1) joint visual attention
2) cycles of collaborative / individual work","1) Gaze
2) Gaze","1) Visual Attention
2) Visual Attention","1) group
2) individual","1) I
2) I","1) calculation
2) calculation","A) learning gains
B) collaboration quality
C) task performance","A) pre-post test
B) Meier Spada Rummel coding scheme
C) number of mazes solved","A) learning
B) coordination, communication
C) performance","A) product
B) process
C) product","1-B: correlation: sig: r = 0.341
2-B: correlation: sig: r = 0.347
2-A: correlation: sig: r = 0.398
2-C: correlation: sig: r = 0.355"
27,42,steph,"I) Eye gaze
VI) Log data","I) Eye gaze
VI) Log data","I) eye-tracker
VI) digital","I)  Tobii 1750 eye-trackers
VI) Tetris ","1) gaze location
2) gaze saccade
3) gaze fixation
4) player actions
5) zoid acceleration","1) Gaze
2) Gaze
3) Gaze
4) Log Data
5) Log Data","1) Visual Attention
2) Eye Motion
3) Visual Attention
4) Task-related
5) Task-related ","1) individual
2) individual
3) individual
4) individual
5) individual","1) I
2) I
3) I
4) VI
5) VI","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation",A) social context,A) experimental set-up,A) group composition,A) condition,1+2+3+4+5-A: sup. machine learning: sig: (ACC:81.43%)
28,43,callie,III) Audio,III) Audio,III) microphone,III) NS,"1) pitch
2) intensity
3) voice quality
4) speaking rate
5) proximity
6) convergence
7) synchrony","1) Verbal
2) Verbal
3) Verbal
4) Verbal
5) Verbal
6) Verbal
7) Verbal","1) Speech Features
2) Speech Features
3) Speech Features
4) Speech Features
5) Speech Features
6) Speech Features
7) Speech Features","1) individual
2) individual
3) individual
4) individual
5) group
6) group
7) group","1) III
2) III
3) III
4) III
5) III
6) III
7) III","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation
6) calculation
7) calculation",A) rapport level,A) human coding validated with self-reports,A) interpersonal relationship / perception,A) process,"5-A: correlation: mixed: (Max r 0.842)
6-A: correlation: mixed: (Max r 0.741)
7-A: correlation: mixed: (Max r 0.634)"
29,44,edwin,I) Eye gaze,I) Eye gaze,I) optical see-through head-mounted display,I) NS,1) gaze location,1) Gaze,1) Visual Attention,1) individual,1) I,1) none,"A) quality of remote collaboration
B) task completion time","A) seven-point scale questionnaire
B) timer","A) performance
B) performance","A) product
B) product","1-A: Wilcoxon Signed Ranks test: sig
1-B: Wilcoxon Signed Ranks test: sig"
30,46,bert,I) Eye gaze,I) Eye gaze,I) eyetracker,I) SMI Glasses,1) joint visual attention,1) Gaze,1) Visual Attention,1) group,1) I,1) calculation,"A) task performance
B) learning gains","A) calculation
B) pre post test","A) performance
B) learning","A) product
B) product","1-A: correlation: sig: (r = 0.59)
1-B: correlation: sig: (r = 0.42)"
31,47,edwin,"II) Video
III) Audio","II) Video
III) Audio","II) camera
III) microcone","II) NS
III) NS","1) intra-personal features
2) dyadic features
3) one vs all features","1) Head
2) Head
3) Verbal","1) Facial Expressions
2) Facial Expressions
3) Speech Features","1) individual
2) group
3) group","1) II&III
2) II&III
3) II&III","1) other: openSMILE, Motion Energy Image
2) calculation
3) calculation","A) personality traits
B) social impressions","A) self-reported survey
B) questionnaire","A) group composition
B) interpersonal relationship / perception","A) condition
B) process","1-A: Regression: 73.53%
1-B: Regression: 76.47%
2-A: Regression: 60.54%
2-B: Regression: 66.42%
3-A: Regression: 65.69%
3-B: Regression: 73.53%"
32,48,bert,"II) Video
III) Audio","II) Video
III) Audio","II) camera
III) microphone","II) NS
III) NS","1) audio energy features
2) visual focus of attention","1) Verbal
2) Gaze","1) Speech Features
2) Visual Attention","1) individual
2) individual","1) III
2) II","1) calculation
2) calculation",A) visual dominance ratio,A) manual annotation of videos,A) group composition,A) condition,1+2-A: sup. machine learning: (79.4%)
33,49,steph,"II) Video
III) Audio
V) Log data
X) computer screen recording","II) Video
III) Audio
V) Log data
X) Log data","II) camera
III) microphone
V) digital
X) digital","II) NS
III) NS
V) FACT (Formative Assessment using Computational Technology)
X) NS","1) card movements
2) scrolling
3) zooming
4) audio features","1) Log Data
2) Log Data
3) Log Data
4) Verbal","1) Task-related 
2) Task-related 
3) Task-related 
4) Speech Features","1) individual
2) individual
3) individual
4) individual","1) V
2) V
3) V
4) III","1) calculation
2) calculation
3) calculation
4) calculation","A) collaboration
B) asymmetric contribution
C) cooperation","A) manual annotation of videos
B) manual annotation of videos
C) manual annotation of videos","A) coordination, communication
B) coordination
C) coordination, communication","A) process
B) process
C) process","1+2+3+4-A+C: sup. machine learning: (96%)
1+2+3+4-A+B+C: sup. machine learning: (86%)"
34,50,edwin,III) Audio,III) Audio,III) NS,III) NS,1) speech utterances,1) Verbal,1) Speech Content,1) individual,1) III,1) calculation,A) personality traits,"A) self-reported survey , perceived interaction scores",A) group composition,A) condition,1-A: sup. machine learning: (87.9%)
35,52,steph,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) EyeTribe,"1) gaze area of interest 
2) cross-recurrence quantification analysis
3) multidimensional recurrence quantification analysis","1) Gaze
2) Gaze
3) Gaze","1) Visual Attention
2) Visual Attention
3) Visual Attention","1) individual
2) group
3) group","1) I
2) I
3) I","1) calculation
2) matrix calculation
3) matrix calculation","A) construction of shared knowledge
B) negotiation
C) coordination
D) task score
E) group performance","A) manual annotation of videos
B) manual annotation of videos
C) manual annotation of videos
D) expert coding of task, post-test score
E) self-reported survey","A) coordination
B) coordination
C) coordination
D) performance
E) performance","A) process
B) process
C) process
D) product
E) product","2-A: regression: sig 
3-B: regression: sig
3-C: regression: sig
2-D: regression: nonsig
2-E: regression: sig
2-D: regression: nonsig
2-E: regression: nosig"
36,53,bert,"I) Eye gaze
III) Audio","I) Eye gaze
III) Audio","I) eye-tracker
III) microphone","I) Tobii X1
III) NS","1) joint visual attention
2) simple linguistic features
3) convergence of linguistic styles
4) coherence","1) Gaze
2) Verbal
3) Verbal
4) Verbal","1) Visual Attention
2) Speech Content
3) Speech Content
4) Speech Content","1) group
2) individual
3) group
4) group","1) I
2) III
3) III
4) III","1) calculation
2) calculation
3) calculation
4) calculation","A) learning gains
B) collaboration
C) joint visual attention","A) pre-post test
B) Coding scheme
C) calculation","A) learning
B) coordination, communication
C) coordination, communication","A) product
B) process
C) process","3-A,B,C: correlation: nonsig
4-A: correlation: sig
4-C: ANOVA: sig
2-A: sup. machine learning: 75%"
37,54,steph,"III) Audio
II) Video","III) Audio
II) Video","III) microphone
II) camera","III) Dev-Audio’s Microcone
II) Logitech Webcam PRO 9000","1) speaking activity
2) visual attention
3) audio-visual","1) Verbal
2) Gaze
3) Gaze","1) Speech Participation
2) Visual Attention
3) Visual Attention","1) individual
2) individual
3) individual","1) III
2) II
3) III&II","1) calculation
2) calculation
3) calculation","A) personality traits
B) percieved interaction score
C) ranked dominance
D) task performance
E) perceived leadership and dominance","A) NEO-FFI, PRF
B) questionnaire 
C) questionnaire
D) expert grading
E) questionnaire","A) group composition
B) interpersonal relationship / perception
C) interpersonal relationship / perception
D) performance
E) interpersonal relationship / perception","A) condition
B) process
C) process
D) product
E) process","1*3-E: sup. machine learning: (50%)
1*3-C: sup. machine learning: (59.1%)"
38,56,bert,"I) Eye gaze
III) Audio
IV) Kinesiology
VI) EDA","I) Eye gaze
III) Audio
IV) Body language
VI) Physiological","I) Mobile eye-tracker
III) microphone
IV) Kinect v2
VI) Smart wristband","I) Tobii
III) kinect microphone
IV) Microsoft
VI) Empatica E4","1) coh-metrix indices
2) physical synchrony
3) physiological synchrony
4) joint visual attention","1) Verbal
2) Body
3) Physiological
4) Gaze","1) Speech Features
2) Gross Body Motion
3) EDA
4) Visual Attention","1) individual
2) group
3) group
4) group","1) III
2) IV
3) VI
4) I","1) calculation
2) calculation
3) calculation
4) calculation","A) learning gains
B) collaboration
C) coh-metrix indices","A) pre-post test
B) Meier Spada Rummel coding scheme
C) computational measures of transcripts","A) learning
B) coordination, communication
C) communication","A) product
B) process
C) process","1-A: correlation: sig
1-B: correlation: sig
1-C: correlation: sig
2-C: correlation: sig
3-C: correlation: sig
4-C: correlation: sig
2-B: sup. machine learning: 84%"
39,57,callie,"VI) EDA
VII) ECG","VI) Physiological
VII) Physiological","VI) wearable sensor
VII) wearable sensor","VI) MP150 Data Acquisition System
VII) MP150 Data Acquisition System","1) SM - EDA
2) IDM - EDA
3) DA - EDA
4) CC - EDA
5) WC - EDA
6) SM - HR
7) IDM - HR
8) DA - HR
9) CC - HR
10) WC - HR low frequency
11) WC - HR high frequency","1) Physiological
2) Physiological
3) Physiological
4) Physiological
5) Physiological
6) Physiological
7) Physiological
8) Physiological
9) Physiological
10) Physiological
11) Physiological","1) EDA
2) EDA
3) EDA
4) EDA
5) EDA
6) Heart
7) Heart
8) Heart
9) Heart
10) Heart
11) Heart","1) group
2) group
3) group
4) group
5) group
6) group
7) group
8) group
9) group
10) group
11) group","1) VI
2) VI
3) VI
4) VI
5) VI
6) VII
7) VII
8) VII
9) VII
10) VII
11) VII","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation
6) calculation
7) calculation
8) calculation
9) calculation
10) calculation
11) calculation","A) task performance
B) self-rated workload","A) Multiattribute Task Battery program
B) Questionnaire (NASA Task Load Index)","A) performance
B) cognitive engagement","A) product
B) process","1-A: LME: nonsig
2-A: LME: nonsig
3-A: LME: sig
4-A: LME: nonsig
5-A: LME: nonsig
6-A: LME: nonsig
7-A: LME: nonsig
8-A: LME: nonsig
9-A: LME: nonsig
10-A: LME: nonsig
11-A: LME: nonsig
1-B: LME: nonsig
2-B: LME: nonsig
3-B: LME: nonsig
4-B: LME: nonsig
5-B: LME: nonsig
6-B: LME: nonsig
7-B: LME: nonsig
8-A: LME: nonsig
9-A: LME: nonsig
10-A: LME: nonsig
11-A: LME: nonsig"
40,58,edwin,II) Video,II) Video,II) camera,II) NS,"1) count of faces looking at screen
2) distance between learners
3) distance between hands
4) hand motion speed","1) Gaze
2) Body
3) Body
4) Body","1) Visual Attention
2) Location
3) Hand Motion
4) Hand Motion","1) individual
2) individual
3) individual
4) individual","1) II
2) II
3) II
4) II","1) calculation
2) calculation
3) calculation
4) calculation","A) physical engagement
B) synchronisation
C) individual accountability","A) Researcher codes
B) Researcher codes
C) Researcher codes","A) cognitive engagement
B) coordination
C) coordination, cognitive engagement","A) process
B) process
C) process","3-C: regression: sig
3-B: regression: sig
1+3-B: regression: sig
3-A: regression: sig"
41,60,edwin,V) Log data,V) Log data,V) touch screen,V) Microsoft PixelSense SDK,1) touch patterns,1) Log Data,1) Touch,1) individual,1) V,1) calculation,A) social regulation,A) Rogat and Linnenbrink-Garcia’s framework,"A) coordination, cognitive engagement",A) process,1-A: calculation: (84.2%)
42,61,steph,"III) Audio
I) Eye gaze
VI) EDA
IV) Kinesiology","III) Audio
I) Eye gaze
VI) Physiological
IV) Body language","III) kinect
I) eye-tracker
VI) wearable sensor 
IV) kinect","III) Kinect
I) Tobii eye-trackers
VI) Empatica E4
IV) Kinect","1) total movement across upper body joints and body parts
2) talking time","1) Body
2) Verbal","1) Gross Body Motion
2) Speech Participation","1) individual
2) individual","1) IV
2) III","1) calculation
2) calculation",A) collaboration quality,A) experimenter code,"A) coordination, communication",A) process,"1-A: correlation: sig
2-A: correlation: sig"
43,62,steph,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) NS,1) EVT of spatial entropy,1) Gaze,1) Visual Attention,1) individual,1) I,1) calculation,"A) collaboration outcome
B) post-test score","A) NS
B) Pre-post test","A) performance
B) learning","A) product
B) product","1-A: regression: sig
1-B: regression: sig"
44,63,iulian,"II) Video
III) Audio
VI) EDA","II) Video
III) Audio
VI) Physiological","II) camera
III) microphone
VI) wearable sensor","II) 360 video camera MOORE system
III) 360 video camera MOORE system
VI) Empatica E3","1) facial expression
2) physiological simultaneous arousal","1) Head
2) Physiological","1) Facial Expressions
2) EDA","1) individual
2) group","1) II
2) VI","1) calculation
2) calculation","A) type of working activity
B) type of interaction","A) Researcher codes
B) Researcher codes","A) coordination
B) communication","A) process
B) process","1-A: calculation: nonsig
1-B: ANOVA: sig
2-A: calculation: nonsig
2-B: calculation: nonsig"
45,64,iulian,"III) Audio
IV) Kinesiology
V) Log data","III) Audio
IV) Body language
V) Log data","III) microphone
IV) wearable sensor
V) digital","III) NS
IV) NS 
V) NS","1) speaking turn features
2) acoustic features
3) head motion features
4) linguistic features","1) Verbal
2) Verbal
3) Head
4) Verbal","1) Speech Participation
2) Speech Features
3) Head Motion
4) Speech Content","1) group
2) individual
3) individual
4) individual","1) III
2) III
3) IV
4) V","1) calculation
2) calculation
3) calculation
4) calculation",A) artefact quality,A) Researcher codes,A) performance,A) product,1*2*3*4-A: unsup. machine learning: sig
46,66,bert,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) Tobii,1) network features,1) Gaze,1) Visual Attention,1) individual,1) I,1) Other (network analyses),A) collaboration quality,"A) Meier, Spada and Rummel coding scheme","A) coordination, communication",A) process,"1-A: sup. machine learning: (85-100%)
1-A: correlation: sig"
47,69,steph,"IV) Kinesiology
VI) Kinesiology
III) Audio
V) Log data","IV) Body language
VI) Body language
III) Audio
V) Log data","IV) kinect
VI) kinect
III) microphone
V) arduino IDE ","IV) Logitech C920
VI) Microsoft Kinect
III) NS
V) Arduino","1) number of faces looking at screen
2) mean distance between learners 
3) mean distance between hands
4) mean hand movement speed
5) mean audio level
6) arduino measure of complexity
7) arduino active hardware blocks
8) arduino active software blocks
9) arduino active blocks
10) student work phases","1) Head
2) Body
3) Body
4) Body
5) Verbal
6) Log Data
7) Log Data
8) Log Data
9) Log Data
10) Log Data","1) Head Motion
2) Location
3) Hand Motion
4) Hand Motion
5) Speech Features
6) Task-related
7) Task-related
8) Task-related
9) Task-related
10) Task-related","1) group
2) individual
3) individual
4) individual
5) individual
6) individual
7) individual
8) individual
9) individual
10) individual","1) IV
2) VI
3) VI
4) VI
5) III
6) V
7) V
8) V
9) V
10) IV","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation
6) other: Arduino
7) other: Arduino
8) other: Arduino
9) other: Arduino
10) other: experimenter coded",A) artefact quality,A) Researcher codes,A) performance,A) product,1*2*3*4*5*6*7*8*9*10-A: sup. machine learning: (24%)
48,70,steph,"III) Audio
V) Log data ","III) Audio
V) Log data ","III) microphone
V) digital pen","III) NS
V) Anoto","1) pause duration
2) energy
3) articulation rate
4) fundamental frequency
5) peak slope
6) spectral stationarity 
7) writing rate
8) writing area 
9) aspect ration
10) pressure
11) uninterrupted writing 
12) pause distribution/average pauses","1) Verbal
2) Verbal
3) Verbal
4) Verbal
5) Verbal
6) Verbal
7) Log Data
8) Log Data
9) Log Data
10) Log Data
11) Log Data
12) Log Data","1) Speech Participation
2) Speech Features
3) Speech Features
4) Speech Features
5) Speech Features
6) Speech Features
7) Text
8) Text
9) Text
10) Text
11) Text
12) Text","1) individual
2) individual
3) individual
4) individual
5) individual
6) individual
7) individual
8) individual
9) individual
10) individual
11) individual
12) individual","1) III
2) III
3) III
4) III
5) III
6) III
7) V
8) V
9) V
10) V
11) V
12) V","1) calculation
2) calculation
3) calculation
4) calcuation
5) calculation
6) calculation
7) calculation
8) calculation
9) calculation
10) Anoto
11) calculation
12) calculation","A) leadership
B) expertise","A) assigned
B) problem solving performance","A) group composition
B) group composition","A) condition
B) condition","1-A: t-test: sig
3-A: t-test: sig
5-A: t-test: sig
6-A: t-test: sig
5-B: t-test: sig
3-B: t-test: nonsig
1-B: t-test: nonsig
6-B: t-test: nonsig"
49,71,steph,"IV) Kinesiology
V) Log data
III) Audio","IV) Body language
V) Log data
III) Audio","IV) kinect
V) Arduino IDE
III) microphone","IV) NS
V) Arduino
III) microphone","1) faces looking at screen 
2) distance between learners
3) distance between hands
4) number of active blocks
5) variety of hardware blocks
6) variety of software blocks 
7) number of interconnections between blocks 
8) audio level","1) Head
2) Body
3) Body
4) Log Data
5) Log Data
6) Log Data
7) Log Data
8) Verbal","1) Head Motion
2) Location
3) Hand Motion
4) Task-related
5) Task-related
6) Task-related
7) Task-related
8) Speech Features","1) individual
2) individual
3) individual
4) individual
5) individual
6) individual
7) individual
8) individual","1) IV
2) IV
3) IV
4) V
5) V
6) V
7) V
8) III","1) calculation
2) calculation
3) calculation
4) Arduino
5) Arduino
6) Arduino
7) Arduino
8) calculation",A) collaborative problem solving ,A) researcher codes ,"A) coordination, performance","A) process, product","1+2-A: sup. machine learning: sig
8-A: sup. machine learning: sig"
50,73,steph,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) Tobii Pro Glasses 2,1) joint visual attention,1) Gaze,1) Visual attention,1) group,1) I,1) calculation,"A) collaboration quality
B) cycles of collaboration
C) learning gains 
D) task performance","A) researcher codes
B) researcher analysis
C) pre-post test
D) correctness ","A) coordination, communication
B) coordination
C) learning
D) performance","A) process
B) process
C) product
D) product","1-A: correlation: sig
1-A: correlation: sig"
51,74,steph,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) SMI Eye- Tracking Glasses with binocular pupil tracking at 30Hz,1) joint visual attention,1) Gaze,1) Visual attention,1) group,1) I,1) calculation,"A) collaboration quality
B) student performance 
C) learning gains ","A) researcher codes
B) correctness
C) pre-post test","A) coordination, communication
B) performance
C) learning","A) process
B) product
C) product","1-A: correlation: sig
1-B: regression: sig
1-C: correlation: sig"
52,75,steph,IV) Kinesiology,IV) Body language,IV) kinect,IV) Kinect,"1) joint movement
2) joint angle
3) dyad proximity","1) Body
2) Body
3) Body","1) Gross Body Motion
2) Gross Body Motion
3) Location","1) individual
2) individual
3) individual","1) IV
2) IV
3) IV","1) unsup. machine learning
2) unsup. machine learning
3) calculation","A) task performance
B) collaboration
C) learning gains","A) researcher codes
B) researcher codes
C) pre-post test","A) performance
B) coordination, communication
C) learning","A) product
B) process
C) product","1-A: correlation: sig
1-B: correlation: nonsig
2-A: correlation: sig / mixed
3-B: correlation: nonsig
3-A: correlation: sig"
53,78,iulian,"I) Eye gaze
II) Video","I) Eye gaze
II) Video","I) eye tracker
II) eye tracker","I) Tobii X1
II) Tobii X1 eye tracker","1) joint visual attention
2) cognitive load (from pupil size)","1) Gaze
2) Gaze","1) Visual Attention
2) Eye Physiology","1) individual
2) individual","1) I
2) II","1) calculation
2) calculation",A) learning gains,A) pre/post test,A) learning,A) product,"1-A: mediation: sig
2-A: mediation: nonsig"
54,80,iulian,VI) EDA,VI) Physiological,VI) wearable sensor,VI) Empatica S3,"1) signal matching 
2) instantaneous derivative matching 
3) directional agreement
4) pearson’s correlation coefficient 
5) fisher’s z-transform of pearson's correlation coefficient","1) Physiological
2) Physiological
3) Physiological
4) Physiological
5) Physiological","1) EDA
2) EDA
3) EDA
4) EDA
5) EDA","1) group
2) group
3) group
4) group
5) group","1) VI
2) VI
3) VI
4) VI
5) VI","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation","A) collaborative will
B) collaborative learning product
C) dual learning gains","A) self report
B) researcher coded
C) researcher coded","A) interpersonal relationship / perception
B) performance
C) learning","A) process
B) product
C) product","1,3,4,5-A : regression: nonsig
2-A: regression: sig
1,3,4,5-B : regression: nonsig
2-B: regression: sig
1,2,4,5-C: regression: nonsig
3-C: regression: sig"
55,82,iulian,"II) Video
III) Audio","II) Video
III) Audio","II) camera
III) microphone","II) NS
III) NS","1) linguistic features
2) voice features
3) facial expression features","1) Verbal
2) Verbal
3) Head","1) Speech Content
2) Speech Features
3) Facial Expressions","1) individual
2) individual
3) individual","1) III
2) III
3) II","1) calculation
2) calculation: OpenSmile
3) calculation: OpenFace","A) perception of peer helpfulness
B) perception of peer understanding
C) perception of peer clarity","A) questionnaire
B) questionnaire
C) questionnaire","A) interpersonal relationship / perception
B) interpersonal relationship / perception
C) interpersonal relationship / perception","A) process
B) process
C) process","1+2+3-A: correlation: sig
1+2+3-B: correlation: sig
1+2+3-C: correlation: sig
1,2-A: correlation: nonsig
1,2-B: correlation: nonsig
1,2-C: correlation: nonsig
3-A: correlation: sig
3-B: correlation: sig
3-C: correlation: sig"
56,83,iulian,"II) Video
V) Log data","II) Video
V) Log data","II) camera
V) own application","II) NS
V) NS","1) type of activity done in task
2) amount of face and body movement
3) target for discussion partner","1) Log Data
2) Body
3) Log Data","1) Task-related
2) Gross Body Motion
3) Task-related","1) individual
2) individual
3) individual","1) V
2) II
3) II","1) calculation
2) calculation
3) calculation","A) task success score
B) subjective perception of collaboration","A) researcher coded
B) self report","A) performance
B) interpersonal relationship / perception","A) product
B) process","1*2*3-A: correlation: sig
1*2*3-B: correlation: sig"
57,84,iulian,"II) Video
III) Audio
VI) EDA","II) Video
III) Audio
VI) Physiological","II) kinect
III) kinect
VI) wearable sensor","II) NS
III) NS
VI) Empatica E4","1) signal matching
2) instantaneous derivative matching 
3) directional agreement 
4) pearson’s correlation coefficient
5) speech activity","1) Physiological
2) Physiological
3) Physiological
4) Physiological
5) Verbal","1) Combined
2) Combined
3) Combined
4) Combined
5) Speech Participation","1) group
2) group
3) group
4) group
5) group","1) VI
2) VI
3) VI
4) VI
5) III","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation","A) learning gains
B) collaboration quality: dialogue management
C) collaboration quality: reaching consensus
D) colaboration quality: reciprocal interaction
E) collaboration quality: information pooling","A) pre/post tests
B) researcher coded
C) researcher coded
D) researcher coded
E) researcher coded","A) learning
B) communication
C) coordination
D) coordination
E) coordination","A) product
B) process
C) process
D) process
E) process","1,2,3-A: correlation : nonsig
4-A: correlation: sig
5-A: ANOVA : sig
1,2,4-B: correlation : nonsig
3-B: correlation: sig
1,2,4-C: correlation : nonsig
3-C: correlation: sig
1,2,4-D: correlation: nonsig
3-D: correlation: sig
1,2,3-E: correlation : nonsig
4-E: correlation: sig"
58,89,callie,"II) Video
III) Audio","II) Video
III) Audio","II) camera
III) microphone","II) NS
III) NS","1) head/body movement
2) (non)concurrent speaking length
3) speaking turn duration/number
4) interruption","1) Body
2) Verbal
3) Verbal
4) Verbal","1) Gross Body Motion
2) Speech Participation
3) Speech Participation
4) Speech Participation","1) individual
2) individual
3) group
4) group","1) II
2) III
3) III
4) III","1) unsup. machine learning
2) calculation
3) calculation
4) calculation",A) emerging leadership,A) researcher codes,A) group composition,A) condition,"1-A: sup. machine learning: sig
2+3+4-A: sup. machine learning: sig
1+2+3+4-A: sup. machine learning: mixed"
59,90,callie,II) Video,II) Video,II) camera,II) NS,1) visual field of attention on a person features,1) Gaze,1) Visual Attention,1) individual,1) II,1) sup. machine learning; calcuation,A) surveyed and observed emerging leadership,A) questionnaire (The SYstematic method for the Multiple Level Observation of Groups; General Leader Impression Scale) + researcher codes (GLIS-observers),A) group composition,A) condition,"1-A: correlation: mixed
1-A: sup. machine learning: sig"
60,92,callie,"III) Audio
V) Log data","III) Audio
V) Log data","III) Microphone
V) own application","III) Dev audio
V) Cmate","1) speech time and frequency
2) symmetry of speech among group
3) total number of touch actions
4) symmetry of touch actions among group","1) Verbal
2) Verbal
3) Log Data
4) Log Data","1) Speech Participation
2) Speech Participation
3) Touch 
4) Touch","1) individual
2) group
3) individual
4) group","1) III
2) III
3) V
4) V","1) calculation
2) calculation
3) calculation
4) calculation",A) collaboration,A) researcher codes (Meier et al.),"A) coordination, communication",A) process,1+2+3+4-A: sup. machine learning: sig: (85%)
61,93,callie,"III) Audio
V) Log data","III) Audio
V) Log data","III) Microphone
V) own application","III) NS
V) NS","1) speech quantity
2) physical participation quantity
3) number of active participants in group
4) verbal participation symmetry among group
5) physical participation symmetry among group","1) Verbal
2) Log Data
3) Verbal
4) Verbal
5) Log Data","1) Speech Participation
2) Task-related
3) Speech Participation
4) Speech Participation
5) Task-related","1) individual
2) individual
3) group
4) group
5) group","1) III
2) V
3) III
4) III
5) V","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation",A) collaboration,A) researcher codes,A) communication,A) process,1+2+3+4-A: sup. machine learning: sig
62,94,callie,IV) Kinesiology,IV) Body language,IV) kinect,IV) Kinect,"1) time spent individually
2) time spent as a group
3) diversity of collaborative interactions
4) transition probabilities between collaborative state","1) Body
2) Body
3) Body
4) Body","1) Location
2) Location
3) Location
4) Location","1) group
2) group
3) group
4) group","1) IV
2) IV
3) IV
4) IV","1) calculation
2) calculation
3) calculation
4) calculation","A) technical ability
B) social ability
C) time spent in makerspace
D) reported frustration","A) teaching team assessment
B) teaching team assessment
C) N/A
D) survey","A) performance
B) interpersonal relationship / perception
C) performance
D) affective","A) product
B) process
C) product
D) process","1-A: correlation: mixed
2-A: correlation: mixed
2-B: correlation: mixed
4-A: correlation: mixed
4-C: correlation: mixed
4-D: correlation: mixed"
63,96,bert,VI) EDA,VI) Physiological,VI) Electrodes,VI) Shimmer 3GSR ,1) physiological synchrony ,1) Physiological,1) EDA,1) group,1) VI,1) calculation (Multidimensional Recurrence Quantification Analysis; MdRQA)),"A) judgement of confidence
B) mental effort
C) task difficulty
D) task interest
E) emotional valence
F) perceived group performance
G) objective group performance score","A) questionnaire
B) questionnaire
C) questionnaire
D) questionnaire
E) questionnaire
F) questionnaire
G) performance score","A) affective
B) cognitive engagement
C) cognitive engagement
D) cognitive engagement
E) affective
F) performance
G) performance","A) process
B) process
C) process
D) process
E) process
F) product
G) product","1-A: regression: nonsig
1-B: regression: sig: (positive)
1-C: regression: nonsig
1-D: regression: nonsig
1-E: regression: nonsig
1-F: regression: nonsig
1-G: regression: nonsig"
64,97,bert,"VI) EDA
VII) ECG
X) Facial EMG","VI) Physiological
VII) Physiological
X) Facial expression","VI) Electrodes
VII) Electrodes
X) Electrodes","VI) BIOPAC MP150 
VII) BIOPAC EL504
X) BIOPAC EL254S ","1) EDA synchrony
2) smiling synchrony
3) heart rate sychrony","1) Physiological
2) Head
3) Physiological","1) EDA
2) Facial Expressions
3) Heart","1) group
2) group
3) group","1) VI
2) X
3) VII","1) Cross-Recurrence Quantification Analysis (CRQA)
2) Cross-Recurrence Quantification Analysis (CRQA)
3) Cross-Recurrence Quantification Analysis (CRQA)","A) team cohesion
B) routine choice","A) questionnaire
B) researcher codes","A) interpersonal relationship / perception
B) coordination","A) process
B) process","1-A: regression: sig: (negative)
2-A: regression: sig
2-B: regression: sig"
65,99,bert,XI) EEG,XI) Physiological,XI) EEG,XI) emotiv EPOC EEG headset,1) brain synchrony,1) Physiological,1) Brain,1) individual,1) XI,1) calculation,"A) engagement
B) social dynamics","A) questionnaire
B) questionnaire","A) cognitive engagement
B) interpersonal relationship / perception","A) process
B) process","1-A: regression: sig
1-B: regression: sig"
66,101,bert,"III) Audio
II) Video
IV) Kinesiology","III) Audio
II) Video
IV) Body language","III) microphone
II) kinect RGB
IV) kinect ","III) Kinect
II) Kinect
IV) Kinect","1) upper body agitation
2) hand agitation
3) head orientation
4) speaking time/turns","1) Body
2) Body
3) Head
4) Verbal","1) Gross Body Motion
2) Hand Motion
3) Head Motion
4) Speech Participation","1) individual
2) individual
3) individual
4) individual","1) IV
2) IV
3) II
4) III","1) calculation
2) calculation
3) calculation
4) calculation (speech diarization)",A) agreement,A) expert rating,A) coordination,A) process,1+2+3+4-A: sup. machine learning: sig: (75%)
67,103,bert,"VI) EDA
VII) ECG","VI) Physiological
VII) Physiological","VI) wearable sensor
VII) wearable sensor","VI) Huixin Psychorus
VII) Huixin Psychorus","1) EDA synchrony
2) heart rate sychrony","1) Physiological
2) Physiological","1) EDA
2) Heart","1) group
2) group","1) VI
2) VII","1) calculation (SSI)
2) calculation (SSI)",A) collaboration quality,A) researcher codes,"A) coordination, cognitive engagement",A) process,"1-A: sup. machine learning: sig
2-A: sup. machine learning: nonsig"
68,104,bert,I) Eye gaze,I) Eye gaze,I) Tobii 4C,I) Tobii,1) shared gaze,1) Gaze,1) Visual Attention,1) individual,1) I,1) calculation,"A) cognitive load
B) collaboration quality
C) task performance
D) gaze overlap","A) questionnaire
B) self-report
C) Completion time, correctness
D) calculation","A) cognitive engagement
B) coordination, communication
C) performance
D) coordination","A) process
B) process
C) product
D) process","1-A: anova: nonsig
1-B: anova: sig
1-C: anova: sig
1-D: anova: sig"
69,105,bert,II) Video,II) Video,II) camera,II) Canon Vixia HV30,1) body synchronization,1) Body,1) Gross Body Motion,1) group,1) II,1) calculation (optic flow analysis),"A) cooperation
B) cultural style matching
C) language style matching
D) colaughter","A) task outcome (prisoner's dilemna)
B) video coding
C) video coding
D) video coding","A) interpersonal relationship / perception
B) group composition
C) group composition
D) interpersonal relationship / perception","A) process
B) condition
C) condition
D) process","1-A: regression: nonsig
1-B: regression: sig: (neg)
1-C: regression: sig: (neg)
1-D: regression: sig"
70,174,iulian,"III) Audio
V) Log data","III) Audio
V) Log data","III) Microphone
V) Log files","III) NS
V) NS","1) speech time
2) prosodic speech features
3) movement of objects","1) Verbal
2) Verbal
3) Log Data","1) Speech Participation
2) Speech Features
3) Task-related","1) individual
2) individual
3) individual","1) III
2) III
3) V","1) calculation
2) calculation (OpenSMILE)
3) calculation",A) collaboration quality,A) self made researcher coding scheme (4-scale ranging between collaboration and cooperation),A) coordination,A) process,1*2*3-A: sup. machine learning: sig
71,181,iulian,IV) Kinesiology,IV) Body language,IV) video camera array,IV) NS,1) gesture type and location,1) Body,1) Hand Motion,1) individual,1) IV,1) calculation,"A) frequency of utterances
B) subjective workload","A) calculation
B) survey","A) communication
B) cognitive engagement","A) process
B) process","1-A: ANOVA: sig
1-B: ANOVA: sig"
72,182,iulian,"II) Video
III) Audio","II) Video
III) Audio","II) camera
III) microphone","II) NS
III) NS","1) speaking time
2) attention received per person
3) attention given by person","1) Verbal
2) Gaze
3) Gaze","1) Speech Participation
2) Visual Attention
3) Visual Attention","1) individual
2) individual
3) individual","1) III
2) II
3) II","1) calculation
2) calculation
3) calculation",A) extraversion rating,A) Big Marker Five Scale (? researcher coded ?),A) group composition,A) condition,1*2*3-A: sup. machine learning: sig
73,503,steph,I) Eye gaze,I) Eye gaze,I) eye-tracker,I) Applied Science Laboratories (ASL) EyeVision system,1) gaze overlap,1) Gaze,1) Visual Attention,1) group,1) I ,1) regression,A) referential form,A) self-made researcher codes,A) communication,A) process,1-A: regression: nonsig
74,506,iulian,III) Audio,III) Audio,III) microphones,III) NS,"1) duration of speech by each student
2) duration in which each student was only speaker
3) duration of overlapping speech from pairs of students
4) duration of overlapping speech from all people
5) duration of silence for all people
6) prosodic and tone features","1) Verbal
2) Verbal
3) Verbal
4) Verbal
5) Verbal
6) Verbal","1) Speech Participation
2) Speech Participation
3) Speech Participation
4) Speech Participation
5) Speech Participation
6) Speech Features","1) individual
2) individual
3) individual
4) individual
5) individual
6) individual","1) III
2) III
3) III
4) III
5) III
6) III","1) calculation
2) calculation
3) calculation
4) calculation
5) calculation
6) calculation",A) collaboration quality,A) video coded scale of collaboration,A) coordination,A) process,1*2*3*4*5*6-A: sup. machine learning: nonsig
75,(Dis)Engagement Matters: Identifying Efficacious Learning Practices with Multimodal Learning Analytics,,"IV) Kinesiology
II) Video",,"IV) Kinect
II) camera","IV) Microsoft Kinect
II) NS","1) clustered hand/wrist movement
2) object manipulation","1) Body
2) Body","1) Hand Motion
2) Task-related",,"1) IV
2) II",,A) Learning gains,A) pre-post test (references to  principles or mechanisms that confer stability to three example structures) ,A) learning,A) product,1-A: sup. machine learning: sig: (ACC: 76%)
76,Unraveling Students’ Interaction Around a Tangible Interface Using Multimodal Learning Analytics,,"IV) Kinesiology
V) Log data",,"IV) Kinect
V) Own application","IV) Microsoft Kinect
V) Created","1) amount of exploration
2) types of exploration
3) amount of movement
4) type of movement
5) Body synchronization
6) Body distance","1) Body
2) Body
3) Body","1) Task-related
2)  Task-related
3) Gross Body Motion",,"1) V
2) V
3) IV
4) IV
5) IV
6) IV",,"A) learning gains
B) learning gain group (high or low)
C) leadership (driver/passenger)","A) pre-post test
B) pre-post test
C) coding","A) Learning
B) Learning
C) Interpersonal relationship","A) product
B) product
C) process","1-A: correlation: nonsig
2-A: correlation: mixed
3-A: correlation: nonsig
4-A: correlation: sig
4-C: ANOVA: sig
5-A: ANOVA: nonsig
6-A: correlation: nonsig
1,2,3,4,5,6-B: sup. machine learning: sig: (ACC: 100%)"
77,Leveraging mobile eye-trackers to capture joint visual attention in co-located collaborative learning groups,,I) Eye gaze,,I) eyetracker,I) Tobii Glasses,"1) Joint visual Attention
2) Cycles of collaborative / individual work","1) Gaze
2)","1) Visual Attention
2) Task-related",,"1) I
2) I",,"A) learning gains
B) collaboration quality
C) task performance","A) pre-post test
B) Meier Spada Rummel coding scheme
C) number of mazes solved","A) Learning
B) Coordination
C) Performance","A) product
B) process
C) product","1-B: correlation: sig 
2-B: correlation: sig 
2-A: correlation: sig 
2-C: correlation: sig "
78,Does Seeing One Another’s Gaze Affect Group Dialogue? A Computational Approach,,"I) Eye gaze
III) Audio",,"I) eye-tracker
III) microphone","I) Tobii X1
III) NS","1) Joint visual attention
2) simple linguistic features
3) convergence (of linguistic styles)
4) coherence","1) Gaze
2) Verbal","1) Visual Attention
2) Speech Participation",,"1) I
2) III
3) III
4) III",,"A) Learning 
B) Collaboration","A) pre-post test
B) Coding scheme","A) Learning
B) Coordination","A) product
B) process","4-A: correlation: sig
4-B: ANOVA: sig
2-A: sup. machine learning: (75%)"
79,Real-time mutual gaze perception enhances collaborative 4 learning and collaboration quality,,"I) Eye gaze
II) Video",,"I) eye tracker
II) eye tracker","I) Tobii X1
II) Tobii X1 eye tracker","1) joint visual attention
2) cognitive load (from pupil size)","1) Gaze
2) Physiological","1) Visual Attention
2）",,"1) I
2) II",,A) learning gains,A) pre/post test,A) Learning,A) product,"1-A: mediation: sig
2-A: mediation: nonsig"
80,Challenging Joint Visual Attention as a Proxy for Collaborative Performance,22,"I) Eye Gaze
III) Audio
V) Log Data",,"I) eye-tracker
III) computer system audio
V) NS","I) SMI RED 250 Eye-Trackers 250Hz
III) NS 
V) NS","1) Joint Visual Attention
2) Joint Mental Effort 
3) Dialogue","1) Gaze
2) Gaze
3) Speech","1) visual attention
2) visual attention
3) Speech Features ",,"1) I
2) I
3) III
4) V",,A) learning performance,A) task outcome,A) product,A) product,"1-A: ANOVA: sig 
2-A: ANOVA: sig"
81,Deep neural networks for collaborative learning analytics: Evaluating team collaborations using student gaze point prediction,,I) Eye Gaze,,"I) video camera, 
gaze-tracker (deep neural networks)","I) Microsoft Kinect, Gaze following framework (GazeFollow)",1) Joint Visual Attention,1) Gaze,1) Visual Attention,,1) I,,A) learning gains,A) post test,A) product,A) product,1-A: correlation: sig
82,"Utilizing Interactive Surfaces to Enhance Learning, Collaboration and Engagement: Insights from Learners’ Gaze and Speech",,"I) Eye Gaze
III) Audio
V) Log data",,"I) eye-tracker
III) NS
V) application","I) SMI and TOBII eye-tracking glasses of 60Hz
III) NS
V) NS","1) individual gaze (transition from image to text)
2) gaze similarity (collaborative gaze)
3) gaze similarity (gaze transition similarity)
4) speech","1) Gaze
2) Gaze
3) Gaze
4) Verbal","1) Visual Attention
2) Visual Attention
3) Visual Attention
4) Speech Participation",,"1) I
2) I
3) I
4) III",,"A) learning gains (five posters, game on interactive display, gamified quiz - collaborative/competitive)
B) game performance","A1) pre test
A2) post test
A3) final post test
B) experience points",A) Learning,A) product,"1-A1: correlation: sig 
1-A2: correlation: sig 
2-A2: correlation: sig 
2,4-A2: ANCOVA: sig "
83,A Multimodal Exploration of Engineering Students Emotions and Electrodermal Activity in Design Activities,,VI) EDA,,VI) wristband,VI) Empatica E3 EDA sensor,1) mean range-corrected EDA responses,1) Physiological,1) EDA,,1) VI,,"A) topic emotions - negative
B) topic emotions - positive","A) pre post self report survey (Topic Emotions Scale)
B) pre post self report survey (Topic Emotions Scale)",A) cognitive?,A) process?,1-A: corrleation: sig
84,"Multimodal, Multiparty Modeling of Collaborative Problem Solving Performance",,"I) Eye Gaze
II) Video
III) Audio",,"I) eye-tracker
II) web camera
II) Emotient
III) headset","I) Tobii 4C
II) NS
II) NS","1) gaze features (fixation dispersion, number of fixations and mean fixation duration, mean saccade amplitude, joint attention)
2) acoustic-prosodic information (fundamental frequency (pitch), loudness (energy), center frequency and amplitude of the first through third formants, harmonics to noise ratio, jitter, and shimmer)
3) facial features (face area, positive and negative valence, expressivity, face/upper body motion)
4) task content feature","1) Gaze
2) Verbal
3) Head
4) Log Data","1) Visual Attention
2) Speech Features
3) Facial Expressions
4) Task Related",,"1) I
2) III
3) III",,A) task performance,A) AUROC,A) performance,A) product,"1,2,3,4-A: AUROC: sig: (71%)
1-A: AUROC: sig: 0.62
2-A: AUROC: sig: 0.54
3-A: AUROC: sig: 0.61
4-A: AUROC: sig: 0.67"
85,Temporal analysis of multimodal data to predict collaborative learning outcomes,,"I) Eye Gaze
III) Audio 
V) Log data ",,"I) eye-tracker 
III) microphone
V) NS","I) SMI Red
III) NS
V) NS","1) Gaze
2) Entropy
3) Similarity
4) Cognitive load
5) Auto-correlation coefficient
6) Energy
7) Shape of envelope
8) Linear predictive coding
9) Dialog
10)  correct/incorrect/hint feedbacks","1) Gaze
2) Gaze
3) Gaze
4) Gaze
5) Verbal
6) Verbal
7) Verbal
8) Verbal
9) Verbal
10) Log Data","1) Visual Attention
2) Visua Attention
3) Visual Attention
4) Eye Physiology
5) Speech Features
6) Speech Features
7) Speech Features
8) Speech Features
9) Speech Content
10) Task Related",,"1) I 
2) I
3) I
4) I
5) III
6) III
7) III
8) III
9) III
10) V",,A) Learning gains,A)  pre -post test ,A) Learning ,A) product,"9-A: correlation: sig
10-A: correlation: sig
1-A: correlation: nonsig
2-A: correlation: nonsig
3-A: correlation: nonsig
4-A : correlation: nonsig
5-A: correlation: nonsig
6-A: correlation: nonsig
7-A: correlation: nonsig
8-A: correlation: nonsig"
86,Collaboration on Procedural Problems May Support Conceptual Knowledge More than You May Think,,"I) Eye Gaze
III) Audio
V) Log data",,"I) eye-tracker
III) computer audio chat
V) computer","I) NS
III) NS
V) NS","1) hint behavior
2) joint visual attention - collaboration quality
3) moments of good collaboration ","1) Log Data
2) Gaze
3) Log Data","1) Task Related
2) Visual Attention
3) Task Related",,"1) V
2) I
3) III",,"A) learning gain
",A) computer-based isomorphic test forms,A) Learning ,A) product,"2-A: correlation: sig
2-A: correlation: nonsig"
87,An Application of Extreme Value Theory to Learning Analytics: Predicting Collaboration Outcome from Eye-Tracking Data,,I) Eye Gaze ,,I) eye-tracker ,I) NS ,"1) Gaze Visual Agitation
2) Gaze Spatial Entropy
3) Return Levels - EVT ","1) Gaze
2) Gaze
3) Gaze","1) Visual Attention
2) Visual Attention
3) Visual Attention",,"1) I
2) I
3) I",,A) quality of collaboration,A) scores based on comparing concept map with the map created by two experts,A) coordination,A) process,"1-A: ANOVA: nonsig
2-A: ANOVA: nonsig
2-A: correlation: nonsig"
88,Using Dual Eye-Tracking to Evaluate Students' Collaboration with an Intelligent Tutoring System for Elementary-Level Fractions,,I) Eye Gaze,,I) eye-tracker,I) SMI Red 250 Hz,"1) joint visual attention 
2) gaze recurrence ","1) Gaze
2) Gaze","1) Visual Attention
2) Visual Attention",,"1) I 
2) I ",,"A) learning gain - procedural test
B) learning gain - conceptual test","A) pre post test 
B) pre post test ",A) Learning ,A) product,"1-A: correlation: nonsig
1-B: correlation: sig"
89,"Understanding Collaborative Program Comprehension: Interlacing Gaze and Dialogues
",,"I) Eye Gaze
III) Audio",,"I) Eye-tracker 
III) NS","I) Tobii 1750
III) NS","1) Gaze Episodes
2) Dialogue Episodes
3) Gaze Transitions","1) Gaze
2) Speech
3) Gaze","1) Visual Attention
2) Speech Participation
3) Visual Attention",,"1) I
2) III
3) I",,A) Task performance - level of understanding,A) researcher coded,A) performance,A) product,1-A: ANOVA: sig
90,Many are the ways to learn identifying multi-modal behavioral profiles of collaborative learning in constructivist activities,"kavie, zoe","II) Video
III) Audio
V) Log data",,"II) Camera
III) Microphone
V) Log data","II) RGB-D
III)
V) ROSbag","1) Affective States
2) Speech
3) Task-context Features
","1) Gaze
2) Speech
3) ","1) Affective State
2) Speech
3) Text Features",,"1) II
2) II
3) III
4) V
",,"A) Last error
B) Learning gain","A) performance score
B) pre-post test","A) performance
B) learning","A) product
B) product","1-A: Kruskal-Wallis: nonsig
2-B: Kruskal-Wallis: sig: (expressive explorers, silent wanderers)"
91,Looking To Understand: The Coupling Between Speakers’ and Listeners’ Eye Movements and Its Relationship to Discourse Comprehension,kavie,I) Eye Gaze,,I) Eye Tracker,I) ASL,1) Eye Movement,1) Gaze,1) Eye Motion,,1) I,,A) Task performance,A) performance score,A) performance,"A) product
",1-A: ANOVA: sig
92,On the Same Wavelength: Exploring Team Neurosynchrony in Undergraduate Dyads Solving a Cyberlearning Problem With Collaborative Script,"kavie, zoe","III) Audio
VIII) EEG",,VIII) EEG Sensor,VIII) B-Alert X-10,1) Brain synchrony,1) Physiological,1) Brain,,1) VIII,,"A) collaborative problem-solving performance
B) collaborative problem-solving efficiency
","A) researcher coded
B) log data
","A) performance
B) coordination
","A) product
B) process","1-A: positive correlation: sig
1-B: negative correlation: sig"
93,Automatically Recognizing Facial Indicators of Frustration: A Learning-centric Analysis,kavie,IV) Kinesiology,,IV) Kinect,IV) Kinect depth camera,"1) Posture Estimation
2) Hand-to-Face Gesture","1) Body
2) Body","1) Gross Body Motion
2) Gross Body Motion",,"1) IV
2) IV",,"A) learning gain
","A) pre post test
","A) cognitive load
","A) product
",1-A: negative correlation: sig
94,"The relationships between learner variables, tool-usage behaviour and performance",kavie,V) Log Data,,V) Log Data,,1) Task-Context Features,1) Log Data,1) Task Related,,1) V,,A) Task performance,A) researcher coded,"A) perspective
B) argument","A) product
B) product","1-A: Wilcoxon Signed Ranks test: sig
1-B: Wilcoxon Signed Ranks test: sig"
95,Effects of Knowledge Interdependence with the Partner on Visual and Action Transactivity in Collaborative Concept Mapping,kavie,I) Eye Gaze,,I) Eye Tracker,,"1) Concept map fixation time ratio
2) Number of concept-map eye-gaze transitions","1) Gaze
2) Gaze","1) Visual Attention
2) Visual Attention",,"1) I
2) I",,"A) Learning Measures
","A) questionnaire (individual level), research coded (dyad level)
",A) performance,A) product,"1,2-A: negative correlation: sig"
97,The NISPI framework: Analysing collaborative problem-solving from students' physical interactions,zoe,II) Video,,II) camera,II) Microsoft Kinetic,1) physical interactivity,1）Body,1）Gross Body motion,,"1) II
",,A)CPS competencies,A) researcher coded ,A) performance,A) product,1-A: anova: sig
98,Many are the ways to learn identifying multi-modal behavioral profiles of collaborative learning in constructivist activities,zoe,"II) Video
III) Audio
V) Log data",,"II) camera
III) Microphone
V) Log data","II) RGB-D
III) NS
V) Learning Platform","1) Affective States
2) Speech
3) Task- context
4) Gaze","1)Physiological
2)Verbal
3)Log
4) Gaze","1) Affective
2) Speech
3) Task- related 
4) Gaze",,"1) II
2) III
3) V
4) II",,"A) Learning gains 
","A) pre-post test 
",A) Learning ,A) product,"2-A: Kruskal-Wallis: sig 
1,2,3-A: sup. machine learning: sig: (0.89)"
99,"Supervised machine learning in multimodal learning analytics
for estimating success in project-based learning",zoe,"II) Video
III) Audio
V) Log",,"II) Camera
III) microphone
V) log","II) camera
III) Audio
V) learning platform","II) NS 
III) NS 
V) Arduino IDE","1）Total number of faces looking toward the screen (FLLS)
2） Total number of connected Arduino components (IDEVHW) 
7） Mean distance between learners (DBL)
9)    measure of complexity (IDEX) ",,,"1) II 
2) V
3) II 
4) III
5) II
6) II
7) V
8) II
9) V",,A) task performance,A) researcher coded ,A) performance,A) product,"7,2,9,10-A: regression: sig: (best result)"
100,Modelling Collaborative Problem-solving Competence with Transparent Learning Analytics: Is Video Data Enough?,zoe,II) Video,,II) Camera,II) NS,"1) Metrics of frequency
2) Metrics of hands distance","1) Body
2) Body","1) Hand 
2) Hand",,"1) II
2) II",,A) CPS competence,A) Researcher coded ,A) Collaboration,A) process,"1,2-A: machine learning: sig: (0.75)"
101,An Integrated Observing Technic for Collaborative Learning: The Multimodal Learning Analytics Based on the Video Coding and EEG Data Mining,zoe,VIII) EEG,,VIII) EEG,VIII) NS,1) mediation- anxiety level,1) physiology,1) brain,,1) VIII,,A) Learning gains ,A) researcher coded ,A) Learning ,A) product,1-A: Mann-Whitney U and Kruskal-Wllis tests: sig
102,Inter-brain synchrony in teams predicts collective performance,zoe,VIII) EEG ,,"VIII) EEG sensor
","VIII) Emotiv
",1) Inter-brain synchrony ,1) physiology,1) brain,,1) VIII,,A) tasks performance,A) mixed - researcher coded & tests,A) Performance,A) product,1-A: correlation: sig
103,,kavie,"I) Eye Gaze
III) Audio",,"I) Eye Tracker
III) Microphone",,"1) Fixation
2) Phonemic clause","1) Gaze
2) Speech","1) Visual Attention
2) Speech",,"1) I
2) III",,A) Conversational attention,A) researcher coded,A) attention,A) process,"1,2-A: t-test: sig"
104,,kavie,I) Eye Gaze,,I) Eye Tracker,,1) Eye gaze trace,1) Gaze,1) Eye Motion,,1) I,,A) Performance,A) log data,A) performance,A) product,1-A: ANOVA: sig
105,,kavie,"I) Eye Gaze
III) Audio",,"I) Eye Tracker
III) Microphone",I) Eye-link II,"1) Shared gaze
2) Shared voice","1) Gaze
2) Speech","1) Visual Attention
2) Speech",,"1) I
2) III",,A) Task performance,A) log data,A) performance,A) product,"1,2-A: t-test: sig"
106,,kavie,V) Log Data,,V) Log Data,,"1) task properties
2) people's actions
3) message content","1) log data
2) log data
3) log data","1) task-related
2) task-related
3) task-related",,"1) V
2) V
3) V",,A) focus attention,A) log data,A) coordination,A) process,"1, 2, 3-A: sup machine learning: sig: (74.25%)"
107,,kavie,X) BVP,,X) Digital pen,X) DOVE,1) gesture drawing on video feed,1) Body,1) Gesture drawing,,1) X,,A) Task performance,A) log data,A) collaboration,A) process,1-A: ANOVA: sig
108,,kavie,"I) Eye Gaze
III) Audio",,"I) Eye Tracker
III) Microphone",,"1) attention
2) speech","1) Gaze
2) Speech","1) Visual Attention
2) Speaking Time",,"1) I
2) III",,A) quality of collaboration,A) log data,A) collaboration,A) process,"1-A: t-test: nonsig
2-A: t-test: sig"
109,A Look Is Worth a Thousand Words: FullGaze Awareness in Video-MediatedConversation,zoe,"I) Eye Gaze
III) Audio",,II) camera,II) NS,1)  gaze awareness ,1) Gaze,1) Visual Attention,,1) I,,"A) Task Performance 
B) collaboration quality","A) log data
B) log data ","A) performance 
B) collaboration
","A) product
B) process","1-A: ANOVA: sig 
1-B: ANOVA: sig"
110,Recognizing communicative facial expressions for discovering interpersonal emotions in group meetings,zoe,II) Video,,II) camera,II) NS,1) facial expressions,1) Physiological,1) Affective,,1) II,,A) Emotion network,A) researcher coded ,A) collaboration,A) process,1-A: unsup. machine learnig: sig 
113,Coordinating spatial referencing using shared gaze,zoe ,"I)  Eye Gaze
III) Audio",,"I) eyetracker
III) microphone","I)  Eyelink II
III) NS","1) shared gaze
2) shared speech ","1) Gaze
2) Speech ","1) visual attention
2) Speech Features",,"1) I
2) III",,A) task performance ,A) log data ,A) performance,A) product,"1,2-A: t-test: sig "
114,Affective e-Learning: Using “Emotional” Data to Improve Learning in Pervasive Learning Environment,zoe ,"VIII) EEG
VII) ECG
VI) EDA
X) BVP",,VIII) EEG sensor,"VIII) NS
VII) NS
VI) NS
X) NS","1) physiology
2) physiology
3) physiology
4) physiology
","1) physiology
2) physiology
3) physiology
4) physiology
","1) brain
2) brain
3）brain
4）brain",,"1) VIII
2) VII
3) VI
4) X",,A) Affective states,A) self-report ,A) Affective ,A) process,"1,2,3,4-A: machine learning: sig: (86.30%)"
118,Multimodal Analysis of Group Attitudes Towards Meeting Management,zoe,III) Audio,,III) Microphone,III) NS,"1) Speech Features
2) Linguisitc features ","1) Verbal
2) Verbal","1) Speech features 
2) Speech features",,"1) III
2) III",,A) social impressions,A) self report,A) Collaboration,A) process,"1,2-A: sup.machine learning: sig: (93%)"
119,"Toward Open-Microphone Engagementfor Multiparty Interactions",kavie,III) Audio,,III) Microphone,,"1) speech features
2) speech features
3) speech style","1) Verbal
2) Verbal
3) Verbal","1) Speech instructions
2) Adjacent utterances
3) Dialogue style",,"1) III
2) III
3) III",,"A) amplitude difference
B) command usage","A) log data
B) researcher coded","A) Collaboration
B) Coordination","A) process
B) product","1,2,3-A: t-test: sig
1,2,3-B: t-test: sig"
120,Evaluation of user gestures in multi-touch interaction: a case study in pair-programming,kavie,II) Video,,II) Camera,,1) Gesture fluency,1) Body,1) Gesture fluency,,1) II,,A) communicative intent ,A) researcher coded,A) Collaboration,A) process,1-A: ANOVA: sig
121,"Towards Adapting Fantasy, Curiosity and Challenge in
Multimodal Dialogue Systems for Preschoolers",kavie,III) Audio,,III) Microphone,,1) speech features,1) Verbal,1) speech usage,,1) III,,"A) task completion
B) fantasy levels","A) researcher coded
B) researcher coded","A) performance
B) affective","A) product
B) process","1-A: correlation: sig: (r=0.406)
1-B: correlation: sig: (r=0.224)"
122,"Multimodal recognition of personality traits in social interactions
Authors
",zoe,"II) Video
III) Audio",,"II) camera
III) Microphone","III) NS
II) NS","1) Gross body movements 
2) Speech Features ","1) Body
2) Verbal","1) Gross body motions
2) Speech features ",,"1) II
2) III",,A) personality traits (five personality),A) questionnaire,A) group composition,A) Condition,"1,2-A:sup.machine learning: sig: (90%)"
123,Modeling the Personality of Participants During Group Interactions,zoe,"II) Video
III) Audio",,"II) camera
III) Microphone
","III) NS
II) NS","1) Gross body movements 
2) Speech Features ","1) Body
2) Verbal","1) Body
2) speech features ",,"1) II
2) III",,A) personality traits (Extraversion and Locus of Control),A) questionnaire,A) group composition,A) Condition,"1,2- A: sup.machine learning: sig: (90%)"
124,"Automatic prediction of individual performance from"" thin slices"" of social behavior",zoe,"II) Video
III) Audio",,"II) camera
III) Microphone","III) NS
II) NS","1) Gross body movements
2) Speech Features","1) Body
2) Verbal","1) Body
2) Speech features ",,"1) II
2) III",,A) task performance,A) researcher coded,A) product,A) product,"1,2-A: unsup-machine learning: sig: (50%)"
125,Combining audio and video to predict helpers' focus of attention in multiparty remote collaboration on physical tasks,kavie,"II) Video
III) Audio",,"II) Camera
III) Microphone",,"1) gross body movements
2) dialogue","1) Body
2) Verbal","1) worker's actions
2) dialogue ",,"1) II
2) III",,A) focus of attention,A) researcher coded,A) Collaboration,A) process,"1,2-A: sup.machine learning: sig: (81.79%)"
126,Predicting remote versus collocated group interactions using nonverbal cues,kavie,III) Audio,,III) Microphone,,"1) Speaking Length
2) Speaking Turns
3) Successful Interruptions
4) Backchannels
5) Fraction of overlapped speech
6) Fraction of silence","1) Verbal
2) Verbal
3) Verbal
4) Verbal
5) Verbal
6) Verbal
7) Verbal","1) speech features
2) speech features
3) speech features
4) speech features
5) speech features
6) speech features ",,"1) III
2) III
3) III
4) III
5) III
6) III",,"A) type of meeting (collocated or remote)
B) collocated meeting inference
C) remote member participation","A) log data
B) log data
C) log data","A) Group dynamics
B) Group dynamics
C) Group dynamics","A) Condition
B) Condition
C) Condition","2-A: unsup.machine.learning: sig: (70%) 
2-B: unsup.machine.learning: sig: (81%)
1-C: unsup.machine.learning: sig: (50%)"
127,Reciprocal attentive communication in remote meeting with a humanoid robot,kavie,II) Video ,,II) camera,,1) gaze frequency,1) Gaze,1) gaze frequency,,1) II,,A) conversational attention,A) questionnaire,A) attention,A) process,1-A: Tukey’s HSD test: sig
128,Estimating focus of attention based on gaze and sound,zoe,"I) Eye Gaze
III) Audio",,"II) camera
III) Microphone","II) NS
II) NS","1) gaze focus 
2) sound focus","1) Gaze
2) Verbal","1) Visual Attention 
2) speech features ",,"1) II
2) III",,A) focus of attention,A) researcher coded ,A) Group dynamics,A) process,"1,2-A: sup. machine learning: (74.8%)"
129,Gaze quality assisted automatic recognition of social contexts in collaborative Tetris,zoe,"I) Eye Gaze
V) log data ",,"I) Eye Tracker
V) application","I) Tobii 1750
II) NS","1) gaze fixations
2) gaze saccades
3) task actions","1)Gaze
2)Gaze
3) Log","1) Visual Attention
2) Eye Motion
3) task-related ",,"1) I 
2) I
3) V",,A) group contexts ,A) researcher coded ,A) Group dynamics,A) process,"1,2,3-A: sup. machine learning: sig: (81.43%)"
131,Putting the Pieces Together: Multimodal Analysis of Social Attention in Meetings,zoe,"I) Eye Gaze
II) Video
III) Audio",,"II) Camera
III) Microphone","II) NS
III) NS","1) eye gaze directions
2) head movements
3) speech features","1) Gaze
2) Body
3) Verbal","1) visual attention
2) hand motions
3) speech features
",,"1) I
2) II
3) III",,A) focus of attention ,A) researcher coded ,A) Coordination,A) process,"1,2,3-A: sup.machine learning: sig: (94.6%)"
132,Modeling focus of attention for meeting indexing,zoe,"I) Eye Gaze
IV) Kinesiology",,"II) Camera
XI) Motion detecting sensor ","II)NS
XI) Polhemus pose tracker","1) eye gaze directions 
2) head movements","1) Gaze
2) Body","1) visual attention 
2)head motions ",,"1) I 
2) IV",,A) focus of attention ,"A) researcher coded
",A) coordination,A) process,"1,2-A: sup. machine learning: sig: (93%)"
133,Modeling focus of attention for meeting indexing based on multiple cues,zoe,"I) Eye Gaze
III) Audio
IV) Kinesiology",,"II) Camera
III) Microphone
XI) Motion detecting sensor ","II)NS
III) NS
XI) Polhemus pose tracker","1) eye gaze directions 
2) head movements
3) Speech features","1) Gaze
2) Body
3) Verbal","1) visual attention 
2) head motions ",,"1) I 
2) IV",,A) focus of attention ,A) researcher coded,A) coordination,A) process,"1,2,3-A: sup.machine learning: (76%)"
134,Mediated attention with multimodal augmented reality,kavie,I) Eye Gaze,,I) Eye Tracker,,1) reaction time,1) Gaze,"1) visual attention 
2) head motions 
3) speech features ",,1) I,,"A) search time
B) error rate","A) log data
B) researcher coded","A) attention
B) performance","A) process
B) product","1-A: t-test: sig
1-B: t-test: sig"
135,Implicit user-adaptive system engagement in speech and pen interfaces,kavie,"III) Audio
V) Log Data",,"III) Microphone
V) Digital Pen",,"1) speech amplitude
2) pen pressure","1) Verbal
2) Log Data","1) speech features
2) body motions",,"1) III
2) IV",,A) task performance,A) research coded,A) performance,A) product,"1-A: t-test: sig
2-A: t-test: nonsig"
136,Gaze-communicative behavior of stuffed-toy robot with joint attention and eye contact based on ambient gaze-tracking,kavie,I) Eye Gaze,,I) Eye Tracker,,"1) reaction to eye contact
2) user-initiative joint attention","1) Gaze
2) Gaze","1) visual attention
2) visual attention",,"1) I
2) I",,"A) subconscious interest
B) favorable feeling","A) self report
B) self report","A) engagement
B) interpersonal relationship
","A) process
B) process","1-A: t-test: sig
2-B: t-test: sig"
137,Multi-party focus of attention recognition in meetings from head pose and multimodal contextual cues,zoe,"III) Audio
IV) Kinesiology
V) Log Data",,"III)Microphone
II) Camera
V) Log ",,"1) speech features 
2) head rotations 
3) slide data ","1) Verbal
2) Body 
3) Log Data","1) speech features
2) head motions 
3) Task- related ",,"1) III
2) IV
3) V",,A) focus of attention ,"A) researcher coded
",A) coordination,A) process,"1,2,3-A: unsup.machine learning: (46.7%)"
138,Multimodal Real-Time Focus of Attention Estimation in SmartRooms,zoe,IV) Kinesiology,,IV) Camera,,1) head rotation,1) Body,1) head motions,,1) IV,,A) focus of attention ,"A) researcher coded
",A) coordination,A) process,1-A: unsup.machine learning: (85%)
139,,kavie,"II) Video
III) Audio",,"II) Camera
III) Audio",,"1) gesture
2) communication quality","1) Body
2) Verbal","1) gross body motion
2) speech participation",,"1) II
2) III",,A) task performance,A) researcher coded,A) performance,A) product,"1-A: ANOVA: nonsig
2-A: ANOVA: nonsig"
140,,kavie,I) Eye Gaze,,I) Eye Tracker,,1) focus of attention,1) Gaze,1) visual attention,,1) I,,"A) task performance
B) quality of assistance
C) communication efficiency","A) log data
B) questionnaire
C) ","A) performance
B) coordination
C) coordination","A) product
B) process
C) process","1-A: ANOVA: sig
1-B: ANOVA: sig
1-C: ANOVA: sig"
141,,kavie,IV) Kinesiology,,IV) Camera,,1) head rotation,1) Body,1) head motions,,1) IV,,"A) peripheral awareness
","A) researcher coded
","A) coordination
",A) process,1-A: t-test: sig
142,,zoe,VIII) EEG ,,"VIII) EEG sensor
","VIII) Enobio EEG
",1) brain waves patterns ,1) physiology,1）brain,,1) VIII,,A) Situational Interest ,A) questionnaire,A) coordination,A) process,1-A: sup.machine learning: (93.3%)
143,,kavie,I) Eye Gaze,,I) Eye Tracker,,1) eye movements,1) Gaze,1) visual attention,,1) I,,"A) early disambiguation
B) orienting effect","A) log data
B) researcher coded","A) communication
B) coordination ","A) process
B) process","1-A: ANOVA: sig
1-B: t-test: sig"
144,,kavie,III) Audio,,III) Microphone,,1) speech time,1) Verbal,1) speech features,,1) III,,"A) speaking dynamics
B) group interactivity level
C) distraction level","A) log data
B) researcher coded
C) researcher coded","A) group dynamics
B) engagement
C) engagement","A) process
B) process
C) process","1-A: ANOVA: sig
1-B: ANOVA: sig
1-C: ANOVA: sig"
145,,kavie,"III) Audio
IV) Kinesiology",,"III) Microphone
IV) Camera",,"1) speaking length
2) speaking energy
3) motion activity","1) Verbal
2) Verbal
3) Body","1) speech features
2) speech features
3) gross body motion",,"1) III
2) III
3) IV",,A) perceived dominance,A) researcher coded,A) group dynamics,A) process,"1-A: sup. machine learning: (85%)
2-A: sup. machine learning: (82%)
3-A: sup. machine learning: (62%)"
146,Visual focus of attention estimation from head pose posterior probability distributions,zoe,IV) Kinesiology,,II) Camera,,1) head pose,1) Body,1) head motions,,1) IV,,A) focus of attention ,"A) researcher coded
",A) coordination,A) process,1-A: unsup.machine learning: sig: (53.6%)
147,Towards High-Level Human Activity Recognition through Computer Vision and Temporal Logic,zoe,"II) Video
III) Audio
IV) Kinesiology",,"II) Camera
III) Microphone
IV) Camera",,"1) focus of attention
2) gestures
3) speech features ","1) Gaze
2) Body
3) Verbal","1) visual attention
2) gross body motion
3) speech features ",,"1) II
2) IV
3) III",,A) group activity,A)researcher coded,A) group dynamics,A) process,"1,2,3-A: unsup.machine learning: (74.4%)"
148,Biosignals reflect pair-dynamics in collaborative work: EDA and ECG study of pair-programming in a classroom environmen,zoe,"VI) EDA
VII) ECG",,"VI) wearable sensor
VII) wearable sensor","VI) Shimmer 3+ GSR devices
VII)  eMotion Faros 180",1) Social Physiological Compliance (SPC),"1) Physiology
",1) combined,,1) VI& VII,,A) task performance,A) log data ,A) performance,A) product,1-A: minimum-width envelope: sig
149,"Toward Automated Detection of Phase Changes in Team Collaboration
",zoe,III) Audio,,III) Microphone,,1) speech features,1) Verbal,1) speech features,,1) III,,A) team coordination,A) researcuer coded,A) coordination,A) process,1-A: sup.machine learning: (40%)
150,Modeling People's Focus of Attention,zoe,IV) Kinesiology,,IV) Camera,,1) head rotation,1) Body,1) head motions,,1) IV,,A) focus of attention ,"A) researcher coded
",A) coordination,A) process,1-A: unsup.machine learning: (93%)
151,,kavie,"VI) EDA
VII) ECG
?) Breathing (changes in lung volume) ",,"VI) Wearable sensor, Wristband
VII) ECG
?) ",,1) Physiological Compliance ,1) Physiology,1) Physiological Compliance,,"1) VI, VII, ?",,"A) task completion time
B) collision damage
C) team coordination","A) log data
B) researcher coded
C) researcher coded","A) performance
B) performance
C) coordination","A) product
B) product
C) process","1-A: regression: sig
1-B: regression: nonsig
1-C: regression: nonsig"
152,,kavie,"III) Audio
V) Log Data",,"III) Microphone
V) Log Data",,"1) verbal participation
2) physical participation","1) Verbal
2) Log","1) speech features
2) physical participation",,"1) III
2) V",,A) group collaboration level,"A) researcher coded
",A) collaboration,A) process,"1,2-A: unsup.machine learning: (60%)"
153,,kavie,"I) Eye Gaze
III) Audio",,"I) Eye Tracker
III) Microphone",,"1) amount of eye gaze at others
2) amount of mutual gaze
3) amount of speech
4) breaking a silence","1) Gaze
2) Gaze
3) Verbal
4) Verbal","1) visual attention
2) visual attention
3) speech features
4) speech particpation",,"1) I
2) I
3) III
4) III",,A) Conversational dominance,A) questionnaire,A) group dynamics,A) process,"1,2,3,4-A: regression: sig"